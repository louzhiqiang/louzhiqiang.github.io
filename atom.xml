<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>痒痒 团团 和 咘咘</title>
  
  <subtitle>一切都是最好的安排</subtitle>
  <link href="https://github.com/louzhiqiang/louzhiqiang.github.io.git/atom.xml" rel="self"/>
  
  <link href="https://github.com/louzhiqiang/louzhiqiang.github.io.git/"/>
  <updated>2023-11-09T14:24:34.259Z</updated>
  <id>https://github.com/louzhiqiang/louzhiqiang.github.io.git/</id>
  
  <author>
    <name>zhiqiang.lou</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>技术管理--为什么要转做管理</title>
    <link href="https://github.com/louzhiqiang/louzhiqiang.github.io.git/2023/11/07/%E6%8A%80%E6%9C%AF%E7%AE%A1%E7%90%86-%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E8%BD%AC%E5%81%9A%E7%AE%A1%E7%90%86/"/>
    <id>https://github.com/louzhiqiang/louzhiqiang.github.io.git/2023/11/07/%E6%8A%80%E6%9C%AF%E7%AE%A1%E7%90%86-%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E8%BD%AC%E5%81%9A%E7%AE%A1%E7%90%86/</id>
    <published>2023-11-06T23:40:42.000Z</published>
    <updated>2023-11-09T14:24:34.259Z</updated>
    
    <content type="html"><![CDATA[<h1 id="为什么要转做管理"><a href="#为什么要转做管理" class="headerlink" title="为什么要转做管理"></a>为什么要转做管理</h1><p>关于这个，我想大多数管理者都会思考的问题，但是结论上，并不都是鲜明的。至少我聊过的一些人，会问他们的生涯方向为什么选择这样发展的时候，会发现，他大概率说不出所以然来，这会突然提醒了你一下，我为什么要做这个选择。</p><p>我这里区分两种情况来说：一种是被动式的走法，一种是主动式的选择。这两种方式没有对错，区别只是开始的状态不太一样，第一种很可能是没做好准备，第二种是充分思考之后。</p><h3 id="被动式走法"><a href="#被动式走法" class="headerlink" title="被动式走法"></a>被动式走法</h3><p>这个路子是很多技术人的路数，在不知道什么时候开始，潜移默化地开始做起来了管理工作，下边开始带人，从一个两个到五个六个，中间的说辞就是能力强，要老带新。</p><p>然后就不知不觉开始了管理的路子，中间如果及时醒悟，会折返回去，继续做个大码农。</p><p>如果不能及时醒悟，那你就准备开始自己的管理生涯吧，这时候你是属于被架着走的，你还不能思考管理的本质，或者说是如何管理。</p><p>这样的方式不能说是好坏，赶上好的领导，对你而言是没问题的，从最终形态看你还是成长的。如果领导不好，没有照顾到你的成长，那你只能是看起来的管理者（打杂的），在舒适度上还赶不上团队内的其他的成员。</p><p>所以我把这一步的关键，放在你的leader身上。</p><h3 id="主动式走法"><a href="#主动式走法" class="headerlink" title="主动式走法"></a>主动式走法</h3><p>有一些人就是喜欢管理，这一类人就很厉害了，他从一开始对这个方向就是感兴趣的，这个时候他的思考广度以及对管理本身的思考成熟度会好很多，这个时候不管你的leader是否能帮助到你，你都比前者会思考，这个起跑线就是好的。</p><p>如果leader能帮助到你，那状态就会起飞，整个过程就是正循环的，如果不能帮助到你，通常你会自己感觉到吃力，工作舒适度上会差一些，那管理上的成长就依赖自己对这件事情的思考上了。</p><hr><p>从长远看，你的发展规划中都应该是有管理的，因为想发挥价值的最短路径是团队，而绝对不是个人。</p><p>所以，如果个人不是绝对的技术爱好者，那么就走一下管理的路线吧。</p><p>让我转做管理的核心路径就是一个：发挥自己更大的价值。</p><p>如果干得好，管理是最崇高的职业之一。没有哪一个职业能像管理一样为他人提供学习和成长的机会，让他们懂得承担责任并取得成绩，以及为团队的成功做出贡献。</p><p>在刘建国的课程中，管理从以下五个角度去入手：</p><ul><li>自我倾听，认识自己，从哪儿来，到哪儿去</li><li>角色认知，构建管理的全景图</li><li>管理方法，管理规划、团队建设、任务管理，直白地说就是看方向、带人、做事</li><li>管理沟通，向上、向下、横向沟通</li><li>管理之路，如何在这条路上走的长远</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;为什么要转做管理&quot;&gt;&lt;a href=&quot;#为什么要转做管理&quot; class=&quot;headerlink&quot; title=&quot;为什么要转做管理&quot;&gt;&lt;/a&gt;为什么要转做管理&lt;/h1&gt;&lt;p&gt;关于这个，我想大多数管理者都会思考的问题，但是结论上，并不都是鲜明的。至少我聊过的一些人，会</summary>
      
    
    
    
    <category term="管理" scheme="https://github.com/louzhiqiang/louzhiqiang.github.io.git/categories/%E7%AE%A1%E7%90%86/"/>
    
    
  </entry>
  
  <entry>
    <title>读书笔记-数据库系统内幕（八）</title>
    <link href="https://github.com/louzhiqiang/louzhiqiang.github.io.git/2023/02/04/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E5%86%85%E5%B9%95%EF%BC%88%E5%85%AB%EF%BC%89/"/>
    <id>https://github.com/louzhiqiang/louzhiqiang.github.io.git/2023/02/04/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E5%86%85%E5%B9%95%EF%BC%88%E5%85%AB%EF%BC%89/</id>
    <published>2023-02-04T10:46:05.000Z</published>
    <updated>2023-02-04T10:47:10.478Z</updated>
    
    
    
    
    <category term="读书笔记" scheme="https://github.com/louzhiqiang/louzhiqiang.github.io.git/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="数据库" scheme="https://github.com/louzhiqiang/louzhiqiang.github.io.git/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>读书笔记-数据库系统内幕（七）</title>
    <link href="https://github.com/louzhiqiang/louzhiqiang.github.io.git/2023/02/04/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E5%86%85%E5%B9%95%EF%BC%88%E4%B8%83%EF%BC%89/"/>
    <id>https://github.com/louzhiqiang/louzhiqiang.github.io.git/2023/02/04/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E5%86%85%E5%B9%95%EF%BC%88%E4%B8%83%EF%BC%89/</id>
    <published>2023-02-04T10:45:59.000Z</published>
    <updated>2023-02-04T10:47:00.975Z</updated>
    
    
    
    
    <category term="读书笔记" scheme="https://github.com/louzhiqiang/louzhiqiang.github.io.git/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="数据库" scheme="https://github.com/louzhiqiang/louzhiqiang.github.io.git/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>读书笔记-数据库系统内幕（六）</title>
    <link href="https://github.com/louzhiqiang/louzhiqiang.github.io.git/2023/02/04/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E5%86%85%E5%B9%95%EF%BC%88%E5%85%AD%EF%BC%89/"/>
    <id>https://github.com/louzhiqiang/louzhiqiang.github.io.git/2023/02/04/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E5%86%85%E5%B9%95%EF%BC%88%E5%85%AD%EF%BC%89/</id>
    <published>2023-02-04T10:45:51.000Z</published>
    <updated>2023-02-04T10:46:53.426Z</updated>
    
    
    
    
    <category term="读书笔记" scheme="https://github.com/louzhiqiang/louzhiqiang.github.io.git/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="数据库" scheme="https://github.com/louzhiqiang/louzhiqiang.github.io.git/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>读书笔记-数据库系统内幕（五）</title>
    <link href="https://github.com/louzhiqiang/louzhiqiang.github.io.git/2023/02/04/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E5%86%85%E5%B9%95%EF%BC%88%E4%BA%94%EF%BC%89/"/>
    <id>https://github.com/louzhiqiang/louzhiqiang.github.io.git/2023/02/04/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E5%86%85%E5%B9%95%EF%BC%88%E4%BA%94%EF%BC%89/</id>
    <published>2023-02-04T10:45:43.000Z</published>
    <updated>2023-03-12T03:37:50.156Z</updated>
    
    <content type="html"><![CDATA[<h2 id="第五章-事务的处理和恢复"><a href="#第五章-事务的处理和恢复" class="headerlink" title="第五章  事务的处理和恢复"></a>第五章  事务的处理和恢复</h2><p>为了实现事务的特性，比如ACID相关的特性，事务需要有一套组件来保证这些特性的实现。这里比较重要的组件有事务管理器、锁管理器、页缓存、日志管理器等。</p><p>每一种事务模型对于组件的角色定位是不一样的，在承担的功能上自然也是有差别的。</p><h3 id="缓冲区管理"><a href="#缓冲区管理" class="headerlink" title="缓冲区管理"></a>缓冲区管理</h3><p>数据库一般都是双层存储的使用，也就是内存和磁盘，但是两者的速率和成本的差别，所以使用也是需要一些权衡，这个对于场景中效率的影响比较大。为了提高效率，就像充分利用内存，减少磁盘的读写。从磁盘上是按页读取的，在内存中有个专门的区域用来缓存他，这个机制就是页缓存或者缓冲池。</p><p>页的管理主要就是何时换入，何时换出。一般在固定的空间内，达到阈值就只换出不咋用的。写操作会优先写页内的数据，保证高效。</p><blockquote><p>O_DIRECT标志打开的文件，</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;第五章-事务的处理和恢复&quot;&gt;&lt;a href=&quot;#第五章-事务的处理和恢复&quot; class=&quot;headerlink&quot; title=&quot;第五章  事务的处理和恢复&quot;&gt;&lt;/a&gt;第五章  事务的处理和恢复&lt;/h2&gt;&lt;p&gt;为了实现事务的特性，比如ACID相关的特性，事务需要有一</summary>
      
    
    
    
    <category term="读书笔记" scheme="https://github.com/louzhiqiang/louzhiqiang.github.io.git/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="数据库" scheme="https://github.com/louzhiqiang/louzhiqiang.github.io.git/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>读书笔记-数据库系统内幕（四）</title>
    <link href="https://github.com/louzhiqiang/louzhiqiang.github.io.git/2023/02/04/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E5%86%85%E5%B9%95%EF%BC%88%E5%9B%9B%EF%BC%89/"/>
    <id>https://github.com/louzhiqiang/louzhiqiang.github.io.git/2023/02/04/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E5%86%85%E5%B9%95%EF%BC%88%E5%9B%9B%EF%BC%89/</id>
    <published>2023-02-04T10:45:35.000Z</published>
    <updated>2023-03-05T23:51:33.098Z</updated>
    
    <content type="html"><![CDATA[<h2 id="第四章-B树的实现"><a href="#第四章-B树的实现" class="headerlink" title="第四章 B树的实现"></a>第四章 B树的实现</h2><p>上一章讲了文件的格式，也就是整个索引的存储格式，本章讲述的主要是数据如何组织的，也就是B树的实现。比如键和指针之间的关系，页头和页之间的关系。</p><p>从根节点到叶子节点下降的过程：</p><ul><li>二分搜索如何进行的</li><li>如何收集相关内容并跟踪父节点，用来后续发生节点的分裂或合并。</li></ul><h3 id="页头"><a href="#页头" class="headerlink" title="页头"></a>页头</h3><p>一般用于保存页的定位、维护和优化信息。主要方向是用来做整个页的一个导向，比如基础的页的统计、属性（比如页所在的层数或者右侧叶的指针）。</p><h3 id="魔术"><a href="#魔术" class="headerlink" title="魔术"></a>魔术</h3><p>一般用于校验。或者保存版本之类的。</p><h3 id="同级指针"><a href="#同级指针" class="headerlink" title="同级指针"></a>同级指针</h3><p>同级指针对于范围查询很有帮助，普通的查询也是可能被覆盖到，但是同级指针的缺点也很明显，在更新的时候，合并或者分裂某个节点，对于同级节点也是要照顾到的。而在并发更新中，对于父类节点可能是需要锁来进行协调的。</p><h3 id="最右指针"><a href="#最右指针" class="headerlink" title="最右指针"></a>最右指针</h3><p>对于B树的节点中，指针是要比节点数多一个的，因为范围上，最右侧的节点实际指的是最右侧的指针的右范围集合。逻辑上好理解，实现上，需要使用一个单独的位置来管理。这个数据在分裂和合并的时候，关注点很高。</p><p>有一些实现会选择把这个信息存储在头部信息中。</p><p>有的存储实现，也会把当前页中的最大值作为最右指针的实体实现，这样结构上就是统一的。</p><h3 id="溢出页"><a href="#溢出页" class="headerlink" title="溢出页"></a>溢出页</h3><p>在实际存储中，这是比较常用的手段。但是溢出页的使用是扩展手段，不能当做常规手段，因为性能上，他是降级的。</p><p>对于超大的数据存储，他是有用的，这个溢出页的级别就稍微考究一点。</p><h3 id="二分搜索"><a href="#二分搜索" class="headerlink" title="二分搜索"></a>二分搜索</h3><p>单元格指针本身是有序存储的，而实体不是。那么这个时候就可以在单元格指针数组进行二分，然后定位到中间的这个实体数据，比较之后，再根据左右方向进行下次二分。</p><h3 id="传播分裂和合并"><a href="#传播分裂和合并" class="headerlink" title="传播分裂和合并"></a>传播分裂和合并</h3><p>当分裂和合并产生的时候，总是需要把这样的操作去向上感知，这样下边的节点才会平衡，这个时候会设置对于父节点操作的细节，比如父节点的锁等。</p><h3 id="再平衡"><a href="#再平衡" class="headerlink" title="再平衡"></a>再平衡</h3><p>B树想要提高利用率，比较核心的一点就是平衡，而看平衡与否的核心指标就是每个节点的利用率，也就是数据的填充率，合适的填充率会控制树高，且可以减少页的换入换出等操作，这对于查询的稳定性至关重要。</p><p>这个操作类似于在做节点的负载均衡。</p><p>在做追加的时候，如何快速定位追加点，对于写入影响很大。比较常见的方式就是最右侧追加策略，批量写入的时候效果更好。</p><p>B树一般在构建的时候会选择给每个节点有适当的保留空间，比如70%的填充率，这样的指标对于后续的读写影响都比较大。因为会触发更频繁的分裂和合并。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;第四章-B树的实现&quot;&gt;&lt;a href=&quot;#第四章-B树的实现&quot; class=&quot;headerlink&quot; title=&quot;第四章 B树的实现&quot;&gt;&lt;/a&gt;第四章 B树的实现&lt;/h2&gt;&lt;p&gt;上一章讲了文件的格式，也就是整个索引的存储格式，本章讲述的主要是数据如何组织的，也就</summary>
      
    
    
    
    <category term="读书笔记" scheme="https://github.com/louzhiqiang/louzhiqiang.github.io.git/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="数据库" scheme="https://github.com/louzhiqiang/louzhiqiang.github.io.git/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>读书笔记-数据库系统内幕（三）</title>
    <link href="https://github.com/louzhiqiang/louzhiqiang.github.io.git/2023/02/04/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E5%86%85%E5%B9%95%EF%BC%88%E4%B8%89%EF%BC%89/"/>
    <id>https://github.com/louzhiqiang/louzhiqiang.github.io.git/2023/02/04/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E5%86%85%E5%B9%95%EF%BC%88%E4%B8%89%EF%BC%89/</id>
    <published>2023-02-04T10:45:28.000Z</published>
    <updated>2023-02-04T12:41:53.374Z</updated>
    
    <content type="html"><![CDATA[<h2 id="第三章-文件格式"><a href="#第三章-文件格式" class="headerlink" title="第三章 文件格式"></a>第三章 文件格式</h2><p>在了解了B树的原理之后，还远远没有达到工程实现需要的细节。这里说的文件格式，就是数据实际存储在磁盘上，我们需要考虑的一些细节问题。</p><p>磁盘上数据布局的重要性远大于内存中数据布局的重要性。这个在之前已经提到过，内存中对于数据布局的关注点和磁盘上对于数据布局的关注点是有比较大的差异的。在磁盘上，数据布局可以确保高速访问，还要考虑持久性存储介质的也行、二进制数据的序列化以及反序列化，以及快速找到需要的字段级数据的能力。在内存上，我们关注更多的是数据使用以及在极端性能要求下，数据的计算方式以及对于硬件特性（比如cpu缓存行）等的充分利用。</p><h3 id="二进制编码"><a href="#二进制编码" class="headerlink" title="二进制编码"></a>二进制编码</h3><p>这里要抛出问题，如果数据需要组织成二进制格式的数据，那么你的结构化数据应该如何布局成这段二进制编码，需要考虑的细节点有哪些？</p><blockquote><p>问题分解了，目标也就清晰了，结论也会清晰很多，细节也会更丰富，落地就更可行。</p></blockquote><ul><li>如何以二进制形式表示键和值的记录</li><li>如何将多个值组合成更复杂的结构</li><li>如何实现可变长度的数据类型和数组，甚至更加复杂的多层嵌套数据。</li></ul><blockquote><p>这样的细节去看看hbase、parquet、clickhouse、doris的存储格式，横向对比之后会更有心得。</p></blockquote><p>当处理多字节数值时，务必在编解码时使用相同的字节序，字节序决定了一组字节的先后顺序。</p><blockquote><p>大端 ：按照从左到右的字节去排序</p><p>小端 ：按照从右到左的字节去排序</p><p>这个一般在不同的目标平台（比如macOs 、linux 等）上，这些会有差别，那么在实际使用时，要关注一下。</p></blockquote><p>固定类型的数据一般都有固定长度的编码。对于变长数据，比如字符串或者非固定长度的数组，一般都会使用 size 值 + value的形式进行存储。</p><p>按位打包的数据：布尔值、枚举值 和 标志 。这个思想可以理解为有限值细节到位的表示法，然后利用更大的原始值表示。比如 8 个枚举值 可以用8个比特位来表示存在哪些， 这个组合就是一个短整型整数的表示方式。</p><p>标志 的概念就是用一个位代表某个概念，如果你有八个概念需要标识，就需要八位，也就是用一个短整型就可以表示这八个概念。校验的时候，可以直接使用掩码进行校验，效率很高。也可以位操作提高效率。</p><h3 id="页的管理"><a href="#页的管理" class="headerlink" title="页的管理"></a>页的管理</h3><p>数据在实际存储到磁盘的时候，会按照一些层次逻辑进行管理，方便后续的操作都有一个统一的逻辑，且这个逻辑是高效和可扩展的。页的概念就是比较常见的名词，当然，他在不同的数据库中锁代表的数据粒度可能是有差别的，但是大体作用是差不多的。这里暂且以页来代表这个概念。</p><p>数据在磁盘上的管理可以先用页来作为一个单位，当然，在页之上可能还会有段、块等等，这样的逻辑管理都是用来逐层检索。</p><p>既然我们把存储都划分了页的逻辑，那么对于整个划分给你的空间里，应该如何合理使用，这里在操作添加数据、删除、更新的时候，页的使用如何更加高效。在硬盘上一个比较大的问题就是碎片的整理，比如当前页的空间不够存储当前数据的情况，如何来决策，再比如当前这条数据特别大的时候，对页的选择策略是怎样的。</p><p>这个场景在 GC 场景是很像的。策略上 G1GC 的实现已经比较全面了。在数据库场景，常见的解决方案是分槽页。</p><blockquote><p><a href="https://blog.csdn.net/zhurhyme/article/details/113812047" target="_blank" rel="noopener">https://blog.csdn.net/zhurhyme/article/details/113812047</a></p></blockquote><p>将页组织成槽的集合，在页内会组织出来一个头部以及指针的集合来进行索引。这个过程跟操作系统管理内存的方式也比较相像。</p><p>有了以上关于标志位、枚举值和原始类型的存储背景，就可以进行单元格数据，用来支持B树的落地。</p><blockquote><p>利用分槽页技术之后，在内部，数据实际是有序存储的，按照value的有序性进行存储，这样在检索的时候就会有logn的检索效率。而写入的时候不具有顺序性的，所以为了存储上的顺序性，只能选择在上边槽管理里涉及的指针集合进行调整，这样比较轻量化。也就是这个顺序是逻辑顺序上实现的。</p></blockquote><p>为了高效管理页的使用，以及为了更叫高效地进行回收页，有些数据库会用一个有限空间来存储页的统计信息，用来提效页的管理。针对超大数据，还会设计专门的溢出页进行存储。</p><blockquote><p>为了提高局部性，某些实现会在叶节点上将键和值分开保存。这样检索的时候，可以改善搜索过程中的局部性。不过需要二次访问去找value。</p></blockquote><p>B树使用简单的指针层级结构：页标识符用于在树文件中定位子节点，而单元格偏移量用于在页内定位单元格。</p><h3 id="版本"><a href="#版本" class="headerlink" title="版本"></a>版本</h3><p>一般会从文件命名上标识或者在文件内部的的魔数上去标识或者专门的字段来标识。</p><h3 id="检验和"><a href="#检验和" class="headerlink" title="检验和"></a>检验和</h3><p>常见的方式就是 checksum  以及 循环冗余校验 CRC </p><p>校验和是最弱的保证形式，不能检测多个比特位的损坏。CRC 可以检测突发错误，主要目标是确保数据没有非人为的，意外的变化。多位错误的检测至关重要，因为大部分在通信网络和存储设备中发生的故障都是以这种形式出现的。</p><blockquote><p>非加密hash  和 CRC 不应该用于验证数据是否已经被篡改。对于这类场景，务必使用专为安全性设计的强加密hash。</p></blockquote><p>校验和通常是针对每个页来计算的，并且保存在页的头部。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;第三章-文件格式&quot;&gt;&lt;a href=&quot;#第三章-文件格式&quot; class=&quot;headerlink&quot; title=&quot;第三章 文件格式&quot;&gt;&lt;/a&gt;第三章 文件格式&lt;/h2&gt;&lt;p&gt;在了解了B树的原理之后，还远远没有达到工程实现需要的细节。这里说的文件格式，就是数据实际存储</summary>
      
    
    
    
    <category term="读书笔记" scheme="https://github.com/louzhiqiang/louzhiqiang.github.io.git/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="数据库" scheme="https://github.com/louzhiqiang/louzhiqiang.github.io.git/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>读书笔记--数据库系统内幕（二）</title>
    <link href="https://github.com/louzhiqiang/louzhiqiang.github.io.git/2023/01/31/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E5%86%85%E5%B9%95%EF%BC%88%E4%BA%8C%EF%BC%89/"/>
    <id>https://github.com/louzhiqiang/louzhiqiang.github.io.git/2023/01/31/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E5%86%85%E5%B9%95%EF%BC%88%E4%BA%8C%EF%BC%89/</id>
    <published>2023-01-31T08:58:00.000Z</published>
    <updated>2023-02-01T00:27:04.242Z</updated>
    
    <content type="html"><![CDATA[<h2 id="第二章-B树基础知识"><a href="#第二章-B树基础知识" class="headerlink" title="第二章 B树基础知识"></a>第二章 B树基础知识</h2><p>不可变性是影响数据库设计和实现的核心概念之一。</p><p>B树是从二分搜索树、2-3树、AVL树发展过来的，都是根据场景和数据库业务功能的需求来推动的。</p><h3 id="二分搜索树"><a href="#二分搜索树" class="headerlink" title="二分搜索树"></a>二分搜索树</h3><p>二分搜索树，一个节点的键大于其左子树的存储的任何键，且小于其右子树中存储的任何键。</p><ul><li>从根节点开始一直沿着节点的左指针向下，可以到达叶子层的一个节点，这个节点就是整棵树中最小键以及他的关联值。</li><li>从根节点开始一直沿着节点的右指针向下，可以达到叶子层的一个节点，这个节点就是整棵树中最大键以及他的关联值。</li></ul><p>二分搜索树，如果分布不均衡，最差的情况，时间复杂度会从 logN 退化到 N。</p><p>平衡树 指的是高度为 log2N的树，并且两个子树之间的高度差不大于1。</p><p>树的平衡是通过以最小化树高并将每一边的节点数保持在界限内的方式重新组织节点来完成的。方法之一就是在添加或者删除节点后执行旋转。</p><p>为了保证树的查询效率，要保证树的平衡，才能尽量保证查询复杂度在log2n。然而，由于二分搜索树的扇出较低，就需要不断去进行平衡操作、重定位节点以及更新指针，而这些操作对于磁盘上的数据结构而言，都是致命的。</p><p>想在磁盘上维护二分搜索树，需要注意：</p><ul><li><p>局部性：元素是以随机顺序添加的，所以不能保证新创建的节点是在其父节点附近写入的，这也就意味着节点子指针可能会跨越多个磁盘页。</p><blockquote><p>通过修改树的布局和使用分页二分树，可以在一定程度上优化这个。</p></blockquote></li><li><p>树高，与游历子指针的开销密切相关。树高代表访问磁盘的次数。</p><blockquote><p>低扇出的数据结构在磁盘存储上，都会有这些弊端。</p></blockquote></li></ul><p>综上，适合磁盘的的树必须具有以下属性：</p><ul><li>高扇出，以改善邻近键的数据局部性。</li><li>低高度，减少遍历期间的寻道次数。</li></ul><h3 id="基于磁盘的结构"><a href="#基于磁盘的结构" class="headerlink" title="基于磁盘的结构"></a>基于磁盘的结构</h3><p>持久性介质会由于自己硬件运行的原理，存在一些限制，这些限制是作为这个数据结构是否适合当前介质的主要参考方向。</p><h4 id="机械硬盘"><a href="#机械硬盘" class="headerlink" title="机械硬盘"></a>机械硬盘</h4><p>在旋转型磁盘上，寻道增加了随机读取的成本，因为其需要磁盘旋转和机械磁头运动来将读/写磁头定位到期望的位置。完成了寻道操作，后续读取的操作就快很多了。</p><blockquote><p>旋转型驱动器的最小传送单元是扇区，读或者写的都是整个扇区，大小一般是512字节到4KB不等。</p></blockquote><p>磁头定位是机械硬盘操作中成本最高的部分。这也就是我们说“顺序IO带来正面增效”的主要原因。</p><h4 id="固态硬盘"><a href="#固态硬盘" class="headerlink" title="固态硬盘"></a>固态硬盘</h4><p>固态硬盘的原理有些类似于jvm虚拟机里G1的垃圾回收方式，依靠region管理。SSD的擦除实体是块。他的单位从大到小依次是：晶圆核心、平面、块、页、阵列、串、记忆单元。</p><p>可写或者可读的最小单元是页。块中的页是需要按序写入的。中间有个闪存转换层（FTL）管理页的状态等，这个类似于操作系统对于物理内存的管理。这样中间页ID跟数据的变化，会用这个FTL来兼容，对于上层也就是可以做到透明了。</p><p>在SSD中，随机读取和顺序读取之间的延迟差异并不大。不过由于预取、读取连续的页和内部并行性，还是有差异，这个其实是不同硬件提供的接口是有差异的。</p><h4 id="磁盘存储结构"><a href="#磁盘存储结构" class="headerlink" title="磁盘存储结构"></a>磁盘存储结构</h4><p>磁盘操作的最小单元是块这一事实，是构建有效的磁盘存储结构的主要限制和设计条件。</p><p>想尽办法用好上边的特性，减少磁盘访问。我们可以通过提高局部性，优化结构的内部表示以及减少页外指针数量来实现这一点。</p><blockquote><p>分页二分树：通过将节点分组到页来设计二分数的布局。</p></blockquote><h3 id="B树"><a href="#B树" class="headerlink" title="B树"></a>B树</h3><p>将B树看成是图书馆里的一个巨大的目录室：先选择正确的柜子，然后在柜子里选择正确的架子，接下来在架子上选择正确的抽屉，最后浏览抽屉里的卡片，然后就能定位到自己需要的那一个。B树就是构建了一个帮助快速导航和定位搜索项的层次结构。</p><p>B树节点内的键是按顺序存储的。</p><p>B树可以做到在每个层次跳转的时候，进行一次磁盘传输。</p><p>B树的兄弟节点可以互相关联形成一个双向链表，对于范围查询方便很多。把这些特性跟实际查询的时候的谓词进行关联，会更明确一些查询的细节。</p><p>B树是一种用于组织和导航固定大小页的页组织技术。</p><blockquote><p>B树允许在根节点、内部节点和叶子节点当中的任意层次上进行存储值。</p><p>B+树则仅在叶子节点上存储值，内部节点仅存储分隔键，用于指引搜索算法去找到叶子节点的关联值。而且他是自下而上构建的。</p></blockquote><p>B树节点的分裂和合并都是自下而上的。而且是逐层向上传导的。分裂和合并的过程主要就类似于双链表增加节点和删除节点的过程，这里主要是注意一下指针的变更。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;第二章-B树基础知识&quot;&gt;&lt;a href=&quot;#第二章-B树基础知识&quot; class=&quot;headerlink&quot; title=&quot;第二章 B树基础知识&quot;&gt;&lt;/a&gt;第二章 B树基础知识&lt;/h2&gt;&lt;p&gt;不可变性是影响数据库设计和实现的核心概念之一。&lt;/p&gt;
&lt;p&gt;B树是从二分搜</summary>
      
    
    
    
    <category term="读书笔记" scheme="https://github.com/louzhiqiang/louzhiqiang.github.io.git/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="数据库" scheme="https://github.com/louzhiqiang/louzhiqiang.github.io.git/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>clickhouse--DDL原理</title>
    <link href="https://github.com/louzhiqiang/louzhiqiang.github.io.git/2023/01/31/clickhouse-DDL%E5%8E%9F%E7%90%86/"/>
    <id>https://github.com/louzhiqiang/louzhiqiang.github.io.git/2023/01/31/clickhouse-DDL%E5%8E%9F%E7%90%86/</id>
    <published>2023-01-31T02:28:34.000Z</published>
    <updated>2023-01-31T08:05:34.386Z</updated>
    
    <content type="html"><![CDATA[<h2 id="clickhouse-ddl原理"><a href="#clickhouse-ddl原理" class="headerlink" title="clickhouse ddl原理"></a>clickhouse ddl原理</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;clickhouse-ddl原理&quot;&gt;&lt;a href=&quot;#clickhouse-ddl原理&quot; class=&quot;headerlink&quot; title=&quot;clickhouse ddl原理&quot;&gt;&lt;/a&gt;clickhouse ddl原理&lt;/h2&gt;</summary>
      
    
    
    
    <category term="clickhouse" scheme="https://github.com/louzhiqiang/louzhiqiang.github.io.git/categories/clickhouse/"/>
    
    
    <category term="ddl" scheme="https://github.com/louzhiqiang/louzhiqiang.github.io.git/tags/ddl/"/>
    
  </entry>
  
  <entry>
    <title>读书笔记--数据库系统内幕</title>
    <link href="https://github.com/louzhiqiang/louzhiqiang.github.io.git/2023/01/29/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E5%86%85%E5%B9%95/"/>
    <id>https://github.com/louzhiqiang/louzhiqiang.github.io.git/2023/01/29/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E5%86%85%E5%B9%95/</id>
    <published>2023-01-29T08:33:02.000Z</published>
    <updated>2023-01-31T08:57:03.427Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>这本书我认为是数据库整体理论入门很好的敲门砖。整体氛围两部分：存储引擎和分布式系统。这样的模块划分显然是不够的，比如元数据的管理、缓存管理等，但是他在讲解这两部分内容的时候会穿插进这些知识点，可以自己总结提炼。</p><p>本书很看重数据的存储和分布式两个部分，前者讲述的重点是数据从进入系统到落盘的整个过程中涉及的一些细节，而后者是宏观上数据如何分布，这里都会根据数据的写入、存储、查询三个角度，来串联这里涉及的知识点。                </p><p>在阅读本书的每一遍，都会有一些新的思考，在看每一个章节的知识点的时候，要根据上边涉及的角度，去前后思考一些，这样就会有比较全面的认识。</p><h2 id="第一部分-存储引擎"><a href="#第一部分-存储引擎" class="headerlink" title="第一部分 存储引擎"></a>第一部分 存储引擎</h2><p>存储引擎是可以作为一个单独的组件，负责在内存和磁盘上<strong>存储、检索和管理</strong>数据。数据库是构建在存储引擎之上的应用程序，它提供了表结构、查询语言、索引、事务 和 许多其他有用的特性。对比一下mysql的可插拔引擎的特性，也是这么一个思想。</p><p>不同的引擎是适用于不同的查询场景的，主要参考指标是数据的更新方式、数据范式的设计、数据读写频率、数据schema的变更要求等，基于这些角度可以看当前的引擎的均衡度。</p><blockquote><p>数据库比较应该从清晰界定的目标开始，保证偏差在预期之内。第二步是找到标准场景的用例。第三步是确认场景的负载。</p><p>这里需要弄清楚你场景的一些具体问题，这样测试的目标会更加明确。比如并发量、数据个体大小、读写比例、访问方式、扩容成本等，最终反馈出来就是我们在实际场景中的投入和产出。</p></blockquote><p>所有存储引擎都面临相同的挑战和限制，类比于城市规划：我们为特定的人口数量构建一座城市，并选择是在高度上还是在面积上对这座城市进行扩展，这两种方式都可以将同样数量的人放入该城市，但这些方法导致了截然不同的生活方式。当在高度上建设城市时，人们住在公寓里，人口密度可能会导致面积较小地区的交通流量增加，而在一个面积更大且更加分散的城市中，人们更有可能住在大房子里，但通勤需要走更远的路。</p><blockquote><p>这样的权衡要思考全面的哈，否则某个调优或者操作，可能会导致达不到目标，原因是瓶颈自己没有预期到。</p></blockquote><h3 id="第一章-简介"><a href="#第一章-简介" class="headerlink" title="第一章 简介"></a>第一章 简介</h3><p>数据库的一般大体分为以下几个主要的模块：</p><ul><li><p>传输模块</p><p>这里的传输是指数据库相关的所有传输，比如客户端通信，内部集群通信、集群与外部组件的通信等。</p></li><li><p>查询处理器</p><p>传输模块会将客户端的查询交给查询处理器，对该查询进行词法、语法解析、解释和验证。这里还包括访问控制检查。解析完之后，确认可以执行的时候，就该优化了，首先消除查询中不可能执行的部分与冗余的部分，然后根据内部统计信息（索引基数、近似交集大小等）和数据分布（数据存储在集群中的哪些节点以及传输所需的成本），尝试找到执行查询的最高效方法。优化器就是要通盘考虑存储和查询中涉及的细节点。</p></li><li><p>执行引擎</p><p>查询会以执行计划的形式呈现，执行计划就是为了得到完整结果的一系列操作，但是往往有多种路径可以计算出最终的结果，所以这里也会从多种路径中选择自己最高效的那个。在执行过程中，往往会涉及本地和远程数据的交互，这里还要综合考虑数据的写入，多节点均衡，本地性计算，数据传输等方面。</p></li><li><p>存储引擎</p><p>执行引擎中的本地查询，就是存储引擎的工作，主要涉及以下点：</p><ul><li>事务管理器：调度事务，确保它们不会使数据库处于逻辑不一致的状态。</li><li>锁管理器：为正在运行的事务锁定数据库对象，确保并发操作不会破坏物理数据的完整性。</li><li>访问方法（存储结构）：管理磁盘上的数据访问，并负责组织磁盘上的数据。</li><li>缓冲区管理器：将数据页缓存在内存中。</li><li>恢复管理器：维护操作日志并在出现故障的时候还原系统状态。</li></ul><p>事务管理器和锁管理器是协同负责并发控制的。</p></li></ul><p>内存数据库和硬盘数据库有很大的不同，除了存储介质的差别，在数据结构、数据的组织和优化技术方面也是有自己的侧重点。</p><p>内存数据库的主要限制因素是内存的易失性以及成本。内存数据库要想做到高可用，对运维会要求很高。</p><blockquote><p>非易失性存储器：NVM  (non-volatile memory)</p></blockquote><p>一般为了内存数据的持久性，会选择顺序写入日志文件，减小写放大带来的影响。这份日志是基于磁盘且已经排序的数据结构，日志写入可以是异步的以及分批的。参考hbase的写入。这个日志是可以作为服务启动或者崩溃后恢复的主要依赖。日志的管理也是关键的一个点，分层管理，区分冷热，保证日志文件的可循环管理。</p><p>在硬盘数据库中，他的存储结构通常具有宽树和矮树的形式，分层次加载，核心目标是通过 有限的内存使用加速查询，减小IO的访问。而在内存中，这些一般都是指针的引用值问题，成本小很多。</p><p>按照行的数据布局适合按行访问数据的情况，将整行数据存储在一起可以提高空间局部性。</p><blockquote><p>磁盘上的数据通常是按块访问的，cpu通常也是按照指定最小单位的数据进行数据获取的，放在自己的cpu缓存里。</p></blockquote><p>如果有批量访问单个字段的场景，其实对于行存储的数据库消耗就是存在读放大的，因为他把不想关字段都读取了。</p><p>面相列的数据库适合OLAP相关业务。  一般都有虚拟ID标识行号。</p><p>决定使用列还是行存储，要先了解自己业务里的访问模式。</p><p>数据存储一般是分多层的，宏观上可以看成是内存、硬盘，在硬盘上也可以分SSD以及HHD两个级别。在细节上，数据还会继续划分，比如block、rowset、segment、page 这些级别都是为了在可能定位到数据的粒度，最小化加载，减小读放大，从而控制IO，当在应对更大数据以及更高并发的情况下，提高系统的可用性。</p><p>如果数据记录的顺序遵循搜索键顺序，这种索引就是聚簇索引。反之就是非聚簇索引。</p><p>索引的成本主要是他的更新成本和查询时的读取成本。这里要考虑到索引的大小、根据需要应对的数据量、更新的频率以及写入的数据大小，尤其是对索引更新的大小，这样就能界定出索引的成本，从而可以量化影响。</p><p>二级索引主索引还是到数据条目，这个争论还是比较多的，成本偏向性是有差别的。如果到主索引，对于读会产生二次read的成本。如果到数据条目，对于更新或者重新定位记录，就要承担更新指针带来的成本。后者对于写频繁，且索引比较多的情况下，成本会被放大。</p><blockquote><p>目前存在两种方式都使用的索引，而入二级索引到数据条目，主索引也正常索引到条目，在条目记录指针发生变化的时候，二级索引使用的时候发现数据不对，要去异步更新一次。这样其实可以把批量更新等方式优化进去。</p></blockquote><p>存储结构的三个常见变量：</p><ul><li>是否使用缓冲：每个基于磁盘的数据结构都必须在某种程度上使用缓冲，因为读写磁盘的最小数据传输单元是块。比如B树，一定要有内存缓冲区，分摊io成本。</li><li>使用可变的或者不可变的文件：LSM和B树的区别便是数据是不可变的还是原地更新的。</li><li>是否按照顺序存储值：有序性决定了我们能否有效地扫描记录的范围。</li></ul><p>以上三点在后续数据库优化方向上，是一些基本思考点，但是很重要。因为每个点都界定了一些优化方向。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;这本书我认为是数据库整体理论入门很好的敲门砖。整体氛围两部分：存储引擎和分布式系统。这样的模块划分显然是不够的，比如元数据的管理、缓存管理等</summary>
      
    
    
    
    <category term="读书笔记" scheme="https://github.com/louzhiqiang/louzhiqiang.github.io.git/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="数据库" scheme="https://github.com/louzhiqiang/louzhiqiang.github.io.git/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>clickHouse初识</title>
    <link href="https://github.com/louzhiqiang/louzhiqiang.github.io.git/2022/10/30/clickHouse%E5%88%9D%E8%AF%86/"/>
    <id>https://github.com/louzhiqiang/louzhiqiang.github.io.git/2022/10/30/clickHouse%E5%88%9D%E8%AF%86/</id>
    <published>2022-10-30T12:50:22.000Z</published>
    <updated>2023-01-31T02:29:25.258Z</updated>
    
    <content type="html"><![CDATA[<h1 id="clickhouse初识"><a href="#clickhouse初识" class="headerlink" title="clickhouse初识"></a>clickhouse初识</h1><h2 id="概况"><a href="#概况" class="headerlink" title="概况"></a>概况</h2><p>16年开源，目前9Kstar，大厂用的很多，尤其是字节在clickhouse上的优化是尤其多的。</p><p>c++语言开发。</p><h2 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h2><ul><li>读多于写</li><li>大宽表，读取少量行，且结果不大。</li><li>数据批量写入，更新较少</li><li>事务性不那么强，数据可以选择最终一致性就满足需求。</li><li>schema易变，需求灵活。</li></ul><h2 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h2><ul><li><p>列存</p></li><li><p>数据有序存储</p><blockquote><p>连续IO也能够充分利用操作系统page cache的预取能力，减少page fault。</p></blockquote></li><li><p>主键索引，属于数据布局的一种优化。</p></li><li><p>稀疏索引：minmax  set  ngrambf_v1  tokenbf_v1  bloom_filter</p></li><li><p>数据sharding：随机分片、固定分片、按照列值分片、自定义表达式分片等。分片是集群扩缩容的关键。</p></li><li><p>数据Partitioning：对partition使用表达式配置、支持partition ttl。</p></li><li><p>数据TTL : 支持多种粒度的数据过期，列、行、表、分区，对于自动化管理冷热数据比较合适。</p></li><li><p>有限支持update、delete，通过mutation操作，异步执行，在compaction之后对外生效。</p></li><li><p>主备同步：多副本都可以对外提供查询服务、副本数量不限制、不同shard的副本数可以不同，用来解决热点问题。</p></li><li><p>计算层：</p><ul><li><p>多核并行：数据有横切和竖切，最细的粒度是index granularity，每个cpu可以执行一个index granularity，充分并行执行。</p></li><li><p>分布式计算：体现在任务下发的策略，这个策略对于分布式计算的稳定执行有很大影响。常见的下发策略：</p><ul><li>随机下发</li><li>最近hostname原则：选择与当前下发机器最相近的hostname节点，进行query下发。在特定的网络拓扑下，可以降低网络延时。而且能够确保query下发到固定的replica机器，充分利用系统cache。</li><li>in order：按照特定顺序逐个尝试下发，当前一个replica不可用时，顺延到下一个replica。</li><li>first or random：在In Order模式下，当第一个replica不可用时，所有workload都会积压到第二个Replica，导致负载不均衡。first or random解决了这个问题：当第一个replica不可用时，随机选择一个其他replica，从而保证其余replica间负载均衡。另外在跨region复制场景下，通过设置第一个replica为本region内的副本，可以显著降低网络延时。</li></ul></li><li><p>向量化执行与SIMD:对内存中的列式数据，一个batch调用一次SIMD指令（而非每一行调用一次），不仅减少了函数调用次数、降低了cache miss，而且可以充分发挥SIMD指令的并行能力，大幅缩短了计算耗时。其他引擎常见的弊端：</p><ul><li>对每一行数据都要调用相应的函数，函数调用开销占比高；这是常见的行式数据库的问题。</li><li>存储层按列存储数据，在内存中也按列组织，但是计算层按行处理，无法充分利用CPU cache的预读能力，造成CPU Cache miss严重；这是大多数列存数据库或者计算引擎【比如spark】的方式，列式读取，行式计算。</li><li>按行处理，无法利用高效的SIMD指令；</li></ul></li><li><p>动态代码生成 runtime codegen：代码生成，直观一些看就是减少了代码调用，而且很多操作都标准化了，只要系统优化规则到位，代码生成的效率要比人为方式写的效率要高得多，这点上在spark那里也可以得到体现。</p><blockquote><p>在经典的数据库实现中，通常对表达式计算采用火山模型，也即将查询转换成一个个operator，比如HashJoin、Scan、IndexScan、Aggregation等。为了连接不同算子，operator之间采用统一的接口，比如open/next/close。在每个算子内部都实现了父类的这些<strong>虚函数</strong>，在分析场景中单条SQL要处理数据通常高达数亿行，虚函数的调用开销不再可以忽略不计。另外，在每个算子内部都要考虑多种变量，比如列类型、列的size、列的个数等，存在着大量的if-else分支判断导致<strong>CPU分支预测</strong>失效。</p></blockquote></li><li><p>近似计算：近似估算distinct values、中位数，分位数等多种聚合函数；建表DDL支持SAMPLE BY子句，支持对于数据进行抽样处理。</p></li><li><p>复杂数据类型支持：ClickHouse还提供了array、json、tuple、set等复合数据类型，支持业务schema的灵活变更。</p><blockquote><p>复杂的嵌套，clickhouse是通过提供json来实现的，也配套了丰富的json函数。但是这并不能触发列存计算的很多特性，比如向量化，原因是json本质是行存储。不过最新的官方feature也在优化，针对json实现列存计算。</p><p>目前clickhouse在V22.8版本的更新里，已经升级出一个json对象存储，在存储时，使用类似parquet对于复杂数据的处理，这样在更新、写入、查询的时候，都可以根据路径直接拿到需要的子数据，而不用解析不相关字段。而且这样就可以充分利用列存的相关特性了。</p></blockquote></li></ul></li></ul><p>参考：<br><a href="https://developer.aliyun.com/article/762097?spm=5176.20128342.J_6302206100.1.7c227ba2IPjLHw" target="_blank" rel="noopener">ClickHouse深度揭秘</a></p><p><a href="https://ost.51cto.com/posts/20274" target="_blank" rel="noopener">ClickHouse V22.8 新版本重要特性</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;clickhouse初识&quot;&gt;&lt;a href=&quot;#clickhouse初识&quot; class=&quot;headerlink&quot; title=&quot;clickhouse初识&quot;&gt;&lt;/a&gt;clickhouse初识&lt;/h1&gt;&lt;h2 id=&quot;概况&quot;&gt;&lt;a href=&quot;#概况&quot; class=&quot;</summary>
      
    
    
    
    <category term="clickhouse" scheme="https://github.com/louzhiqiang/louzhiqiang.github.io.git/categories/clickhouse/"/>
    
    
  </entry>
  
  <entry>
    <title>sql面试题汇总</title>
    <link href="https://github.com/louzhiqiang/louzhiqiang.github.io.git/2022/10/27/sql%E9%9D%A2%E8%AF%95%E9%A2%98%E6%B1%87%E6%80%BB/"/>
    <id>https://github.com/louzhiqiang/louzhiqiang.github.io.git/2022/10/27/sql%E9%9D%A2%E8%AF%95%E9%A2%98%E6%B1%87%E6%80%BB/</id>
    <published>2022-10-27T11:17:31.000Z</published>
    <updated>2022-10-27T13:18:30.350Z</updated>
    
    <content type="html"><![CDATA[<p>sql面试题是一个关注不是特别多的地方，很多sql的写法其实也是需要融入算法里的点，尤其是一些分析场景，需要去补全数据。<br>这里把这个链接沉淀下来，后边有需要的时候可以看一下。</p><p><a href="https://blog.51cto.com/u_14932245/4837359" target="_blank" rel="noopener">https://blog.51cto.com/u_14932245/4837359</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;sql面试题是一个关注不是特别多的地方，很多sql的写法其实也是需要融入算法里的点，尤其是一些分析场景，需要去补全数据。&lt;br&gt;这里把这个链接沉淀下来，后边有需要的时候可以看一下。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.51cto.com/u_14932</summary>
      
    
    
    
    <category term="面试" scheme="https://github.com/louzhiqiang/louzhiqiang.github.io.git/categories/%E9%9D%A2%E8%AF%95/"/>
    
    
  </entry>
  
  <entry>
    <title>doris查询原理</title>
    <link href="https://github.com/louzhiqiang/louzhiqiang.github.io.git/2022/10/16/doris%E6%9F%A5%E8%AF%A2%E5%8E%9F%E7%90%86/"/>
    <id>https://github.com/louzhiqiang/louzhiqiang.github.io.git/2022/10/16/doris%E6%9F%A5%E8%AF%A2%E5%8E%9F%E7%90%86/</id>
    <published>2022-10-16T08:17:01.000Z</published>
    <updated>2022-10-16T13:22:46.951Z</updated>
    
    <content type="html"><![CDATA[<h1 id="doris查询原理"><a href="#doris查询原理" class="headerlink" title="doris查询原理"></a>doris查询原理</h1><p>doris的上层mpp部分的查询主要分为四个过程：Analyze，SinglePlan，DistributedPlan，Schedule。这个过程跟presto的过程差不多，两者可以对比这学习。</p><p>Analyze 负责对 AST 进行前期的一些处理，SinglePlan 根据 AST 进行优化生成单机查询计划，DistributedPlan 将单机的查询计划拆成分布式的查询计划，Schedule 阶段负责决定查询计划下发到哪些机器上执行。</p><h2 id="设计目标"><a href="#设计目标" class="headerlink" title="设计目标"></a>设计目标</h2><p>1、最大化计算的并行性：如何划分stage</p><p>2、最小化数据的网络传输：如何分配任务以及中间数据的存储</p><p>3、最大化减少需要扫描的数据：如何做到更加彻底的下推</p><h2 id="查询总架构"><a href="#查询总架构" class="headerlink" title="查询总架构"></a>查询总架构</h2><p><img src="/images/4326a9cad256609a4de27912ddc07e56.png" alt=""></p><p>Analyze 负责对 AST 进行前期的一些处理，SinglePlan 根据 AST 进行优化生成单机查询计划，DistributedPlan 将单机的查询计划拆成分布式的查询计划，Schedule 阶段负责决定查询计划下发到哪些机器上执行。</p><p><img src="/images/d1668d932ee4abf6ecf178b14661cacf.png" alt=""></p><h2 id="sql解析"><a href="#sql解析" class="headerlink" title="sql解析"></a>sql解析</h2><p>词法分析采用 jflex 技术，语法分析采用 java cup parser 技术，最后生成抽象语法树（Abstract Syntax Tree）AST，这些都是现有的、成熟的技术。</p><p>逻辑计划阶段，是从AST转化为代数关系的阶段，代数关系是一棵算子树，每个节点代表一种对数据的计算方式，整棵树代表了数据的计算方式以及流动方向。</p><p>如下：</p><p><img src="/images/a8cfc820f7d4e211c821253e5c9bcf84.png" alt=""></p><blockquote><p>这个方式结合flink的数据流转方式进行思考。</p></blockquote><p>物理计划是在逻辑计划的基础上，根据机器的分布，数据的分布，决定去哪些机器上执行哪些计算操作。</p><p>Doris 系统的 SQL 解析也是采用这些步骤，只不过根据 Doris 系统结构的特点和数据的存储方式，进行了细化和优化，最大化发挥机器的计算能力。</p><h3 id="sql-parser"><a href="#sql-parser" class="headerlink" title="sql parser"></a>sql parser</h3><p>AST 是一种树状结构，代表着一条 SQL。不同类型的查询 select, insert, show, set, alter table, create table 等经过 Parse 阶段后生成不同的数据结构（SelectStmt, InsertStmt, ShowStmt, SetStmt, AlterStmt, AlterTableStmt, CreateTableStmt 等），但他们都继承自 Statement，并根据自己的语法规则进行一些特定的处理。例如：对于 select 类型的 sql， Parse 之后生成了 SelectStmt 结构。</p><p>SelectStmt 结构包含了 SelectList，FromClause，WhereClause，GroupByClause，SortInfo 等结构。这些结构又包含了更基础的一些数据结构，如 WhereClause 包含了 BetweenPredicate（between 表达式）, BinaryPredicate（二元表达式）， CompoundPredicate（and or 组合表达式）, InPredicate（in 表达式）等。</p><p><img src="/images/340f57691764bf70c9601a15631e0005.jpeg" alt=""></p><blockquote><p>以上结构基于不同的解析工具会有不同的节点类型，但是大体结构是一致的。</p></blockquote><h3 id="analyze"><a href="#analyze" class="headerlink" title="analyze"></a>analyze</h3><p>抽象语法树是由 StatementBase 这个抽象类表示。这个抽象类包含一个最重要的成员函数 analyze()，用来执行 Analyze 阶段要做的事。</p><p>不同类型的查询 select, insert, show, set, alter table, create table 等经过 Parse 阶段后生成不同的数据结构（SelectStmt, InsertStmt, ShowStmt, SetStmt, AlterStmt, AlterTableStmt, CreateTableStmt 等），这些数据结构继承自 StatementBase，并实现 analyze() 函数，对特定类型的 SQL 进行特定的 Analyze。</p><p>例如：select 类型的查询，会转成对 select sql 的子语句 SelectList, FromClause, GroupByClause, HavingClause, WhereClause, SortInfo 等的 analyze()。然后这些子语句再各自对自己的子结构进行进一步的 analyze()，通过层层迭代，把各种类型的 sql 的各种情景都分析完毕。例如：WhereClause 进一步分析其包含的 BetweenPredicate（between 表达式）, BinaryPredicate（二元表达式）， CompoundPredicate（and or 组合表达式）, InPredicate（in 表达式）等。</p><blockquote><p>这种解析设计方式是值得借鉴思考的，sql上层会按照不同的业务类型进行不同的具体实现，然后再确定了上层业务之后，底层根据上层的语境进行下属层次的迭代分析。每一种类型都有自己的结构，然后每种结构也会有自己的解析，直到遇到无法解析的就可以进行反馈。</p></blockquote><p><strong>对于查询类型的 SQL，包含以下几项重要工作：</strong></p><ul><li><p><strong>元信息的识别和解析：</strong>识别和解析 sql 中涉及的 Cluster, Database, Table, Column 等元信息，确定需要对哪个集群的哪个数据库的哪些表的哪些列进行计算。</p></li><li><p><strong>SQL 的合法性检查：</strong>窗口函数不能 DISTINCT，投影列是否有歧义，where 语句中不能含有 grouping 操作等。</p></li><li><p><strong>SQL 简单重写：</strong>比如将 select * 扩展成 select 所有列，count distinct 转成 bitmap 或者 hll 函数等。</p></li><li><p><strong>函数处理：</strong>检查 sql 中包含的函数和系统定义的函数是否一致，包括参数类型，参数个数等。</p></li><li><p><strong>Table 和 Column 的别名处理</strong></p></li><li><p><strong>类型检查和转换：</strong>例如二元表达式两边的类型不一致时，需要对其中一个类型进行转换（BIGINT 和 DECIMAL 比较，BIGINT 类型需要 Cast 成 DECIMAL）。</p></li></ul><blockquote><p>以上每个环节都是有各自作用的，而且每一部都很重要，自己之前对于每一步骤其实都有涉及，但是把每个步骤更好的划分，做得不够，可以参考这个架构，好的架构对于规则的扩展很重要。</p></blockquote><p>对 AST 进行 analyze 后，会再进行一次 rewrite 操作，进行精简或者是转成统一的处理方式。<strong>目前 rewrite 的算法是基于规则的方式，针对 AST 的树状结构，自底向上，应用每一条规则进行重写。如果重写后，AST 有变化，则再次进行 analyze 和 rewrite，直到 AST 无变化为止。</strong></p><p>例如：常量表达式的化简：1 + 1 + 1 重写成 3，1 &gt; 2 重写成 Flase 等。将一些语句转成统一的处理方式，比如将 where in, where exists 重写成 semi join, where not in, where not exists 重写成 anti join。</p><h3 id="生成单机逻辑-Plan-阶段"><a href="#生成单机逻辑-Plan-阶段" class="headerlink" title="生成单机逻辑 Plan 阶段"></a><strong>生成单机逻辑 Plan 阶段</strong></h3><p>这部分工作主要是根据 AST 抽象语法树生成代数关系，也就是俗称的算子数。树上的每个节点都是一个算子，代表着一种操作。</p><p>比如常见的算子操作：scan、sort、exchange、hashJoin、project等</p><p><strong>具体来说这个阶段主要做了如下几项工作：</strong></p><ul><li><p><strong>Slot 物化：</strong>指确定一个表达式对应的列需要 Scan 和计算，比如聚合节点的聚合函数表达式和 Group By 表达式需要进行物化。</p></li><li><p><strong>投影下推：</strong>BE 在 Scan 时只会 Scan 必须读取的列。</p></li><li><p><strong>谓词下推：</strong>在满足语义正确的前提下将过滤条件尽可能下推到 Scan 节点。</p></li><li><p><strong>分区，分桶裁剪：</strong>根据过滤条件中的信息，确定需要扫描哪些分区，哪些桶的 tablet。</p></li><li><p><strong>Join Reorder：</strong>对于 Inner Join, Doris 会根据行数调整表的顺序，将大表放在前面。</p></li><li><p><strong>Sort + Limit 优化成 TopN：</strong>对于 order by limit 语句会转换成 TopN 的操作节点，方便统一处理。</p></li><li><p><strong>MaterializedView 选择：</strong>会根据查询需要的列，过滤，排序和 Join 的列，行数，列数等因素选择最佳的物化视图。</p></li></ul><blockquote><p>基于以上优化，可以最大程度减少分布式执行的资源消耗。其实在规则上还远远不止以上这些。</p></blockquote><h3 id="生成分布式-Plan-阶段"><a href="#生成分布式-Plan-阶段" class="headerlink" title="生成分布式 Plan 阶段"></a><strong>生成分布式 Plan 阶段</strong></h3><p>有了单机的 PlanNode 树之后，就需要进一步根据分布式环境，拆成分布式 PlanFragment 树（PlanFragment 用来表示独立的执行单元），毕竟一个表的数据分散地存储在多台主机上，完全可以让一些计算并行起来。</p><blockquote><p>这个计划决定了一个MPP架构数据服务可以支持的场景。</p></blockquote><p>这个步骤的主要目标是<strong>最大化并行度和数据本地化</strong>。主要方法是<strong>将能够并行执行的节点拆分出去单独建立一个 PlanFragment，用 ExchangeNode 代替被拆分出去的节点，用来接收数据</strong>。拆分出去的节点增加一个 DataSinkNode，用来将计算之后的数据传送到 ExchangeNode 中，做进一步的处理。</p><p>这个过程跟spark的物理计划很像，flink的物理计划产出也是这样的，都是在stage之间进行拆解的时候，进行一些输入和输出的节点的增加。</p><blockquote><p>这个过程跟后端架构的搭建很像，增加中间节点往往就可以进行解耦，但是如何做减法，面对的场景可以有更好的扩展性，才是这里最难的。</p></blockquote><p>这一步采用递归的方法，自底向上，遍历整个 PlanNode 树，然后给树上的每个叶子节点创建一个 <strong>PlanFragment</strong>，如果碰到父节点，则考虑将其中能够并行执行的子节点拆分出去，父节点和保留下来的子节点组成一个<strong>parent PlanFragment</strong>。拆分出去的子节点增加一个父节点 DataSinkNode 组成一个 child PlanFragment，child PlanFragment 指向 parent PlanFragment。这样就确定了<strong>数据的流动方向</strong>。</p><p>以join为例：</p><p><strong>Doris 目前支持 4 种 join 算法：</strong>broadcast join，hash partition join，colocate join，bucket shuffle join。</p><p><strong>broadcast join：</strong>将小表发送到大表所在的每台机器，然后进行 hash join 操作。当一个表扫描出的数据量较少时，计算 broadcast join 的 cost，通过计算比较 hash partition 的 cost，来选择 cost 最小的方式。</p><p><strong>hash partition join：</strong>当两张表扫描出的数据都很大时，一般采用 hash partition join。它遍历表中的所有数据，计算 key 的哈希值，然后对集群数取模，选到哪台机器，就将数据发送到这台机器进行 hash join 操作。</p><p><strong>colocate join：</strong>两个表在创建的时候就指定了数据分布保持一致，那么当两个表的 join key 与分桶的 key 一致时，就会采用 colocate join 算法。由于两个表的数据分布是一样的，那么 hash join 操作就相当于在本地，不涉及到数据的传输，极大提高查询性能。</p><p><strong>bucket shuffle join：</strong>当 join key 是分桶 key，并且只涉及到一个分区时，就会优先采用 bucket shuffle join 算法。由于分桶本身就代表了数据的一种切分方式，所以可以利用这一特点，只需将右表对左表的分桶数 hash 取模，这样只需网络传输一份右表数据，极大减少了数据的网络传输，如下图所示bucket shuffle join 示例。</p><p><img src="/images/91e573c81f25c23cb42d967dfb7692be.png" alt=""></p><p>下边看一下HashJoinNode的实现逻辑：</p><ul><li>对 PlanNode，自底向上创建 PlanFragment。</li><li>如果是 ScanNode，则直接创建一个 PlanFragment，PlanFragment 的 RootPlanNode 是这个 ScanNode。</li><li>如果是 HashJoinNode，则首先计算下 broadcastCost，为选择 boracast join 还是 hash partition join 提供参考。</li><li>根据不同的条件判断选择哪种 Join 算法</li><li>如果使用 colocate join，由于 join 操作都在本地，就不需要拆分。设置 HashJoinNode 的左子节点为 leftFragment 的 RootPlanNode，右子节点为 rightFragment 的 RootPlanNode，与 leftFragment 共用一个 PlanFragment，删除掉 rightFragment。</li><li>如果使用 bucket shuffle join，需要将右表的数据发送给左表。所以先创建了一个 ExchangeNode，设置 HashJoinNode 的左子节点为 leftFragment 的 RootPlanNode，右子节点为这个 ExchangeNode，与 leftFragment 共用一个 PlanFragment，并且指定 rightFragment 数据发送的目的地为这个 ExchangeNode。</li><li>如果使用 broadcast join，需要将右表的数据发送给左表。所以先创建了一个 ExchangeNode，设置 HashJoinNode 的左子节点为 leftFragment 的 RootPlanNode，右子节点为这个 ExchangeNode，与 leftFragment 共用一个 PlanFragment，并且指定 rightFragment 数据发送的目的地为这个 ExchangeNode。</li><li>如果使用 hash partition join，左表和右边的数据都要切分，需要将左右节点都拆分出去，分别创建 left ExchangeNode, right ExchangeNode，HashJoinNode 指定左右节点为 left ExchangeNode 和 right ExchangeNode。单独创建一个 PlanFragment，指定 RootPlanNode 为这个 HashJoinNode。最后指定 leftFragment, rightFragment 的数据发送目的地为 left ExchangeNode, right ExchangeNode。</li></ul><p>以下就是上边的过程：</p><p><img src="/images/4197d9e0e18a4d38334937d0bf45e372.png" alt=""></p><p>下图是两个表的 join 操作转换成 PlanFragment 树之后的示例，一共生成了 3 个 PlanFragment。最终数据的输出通过 ResultSinkNode 节点。</p><p><img src="/images/2cf7964d4cb3001834e57532d467ad8d.png" alt=""></p><h3 id="Schedule-阶段"><a href="#Schedule-阶段" class="headerlink" title="Schedule 阶段"></a><strong>Schedule 阶段</strong></h3><p>这一步是根据分布式逻辑计划，创建分布式物理计划。主要解决以下问题：</p><ul><li>哪个 BE 执行哪个 PlanFragment</li><li>每个 Tablet 选择哪个副本去查询</li><li>如何进行多实例并发</li></ul><p>创建物理计划的核心流程：</p><p><img src="/images/f217f1b8f4321424f66d4679b5367945.png" alt=""></p><p><strong>prepare 阶段：</strong>给每个 PlanFragment 创建一个 FragmentExecParams 结构，用来表示 PlanFragment 执行时所需的所有参数；如果一个 PlanFragment 包含有 DataSinkNode，则找到数据发送的目的 PlanFragment，然后指定目的 PlanFragment 的 FragmentExecParams 的输入为该 PlanFragment 的 FragmentExecParams。</p><p> <strong>computeScanRangeAssignment 阶段：</strong>针对不同类型的 join 进行不同的处理。</p><ul><li><strong>computeScanRangeAssignmentByColocate：</strong>针对 colocate join 进行处理，由于 join 的两个表桶中的数据分布都是一样的，他们是基于桶的 join 操作，所以在这里是确定每个桶选择哪个 host。在给 host 分配桶时，尽量保证每个 host 分配到的桶基本平均。</li><li><strong>computeScanRangeAssignmentByBucket：</strong>针对 bucket shuffle join 进行处理，也只是基于桶的操作，所以在这里是确定每个桶选择哪个 host。在给 host 分配桶时，同样需要尽量保证每个 host 分配到的桶基本平均。</li><li><strong>computeScanRangeAssignmentByScheduler：</strong>针对其他类型的 join 进行处理。确定每个 scanNode 读取 tablet 哪个副本。一个 scanNode 会读取多个 tablet，每个 tablet 有多个副本。为了使 scan 操作尽可能分散到多台机器上执行，提高并发性能，减少 IO 压力，Doris 采用了 Round-Robin 算法，使 tablet 的扫描尽可能地分散到多台机器上去。例如 100 个 tablet 需要扫描，每个 tablet 3 个副本，一共 10 台机器，在分配时，保障每台机器扫描 10 个 tablet。</li></ul><p><strong>computeFragmentExecParams 阶段：</strong>这个阶段解决 PlanFragment 下发到哪个 BE 上执行，以及如何处理实例并发问题。确定了每个 tablet 的扫描地址之后，就可以以地址为维度，将 FragmentExecParams 生成多个实例，也就是 FragmentExecParams 中包含的地址有多个，就生成多个实例 FInstanceExecParam。如果设置了并发度，那么一个地址的执行实例再进一步的拆成多个 FInstanceExecParam。针对 bucket shuffle join 和 colocate join 会有一些特殊处理，但是基本思想一样。FInstanceExecParam 创建完成后，会分配一个唯一的 ID，方便追踪信息。如果 FragmentExecParams 中包含有 ExchangeNode，需要计算有多少 senders，以便知道需要接受多少个发送方的数据。最后 FragmentExecParams 确定 destinations，并把目的地址填充上去。</p><p><strong>create result receiver 阶段：</strong>result receiver 是查询完成后，最终数据需要输出的地方。</p><p> <strong>to thrift 阶段：</strong>根据所有 PlanFragment 的 FInstanceExecParam 创建 rpc 请求，然后下发到 BE 端执行。这样一个完整的 SQL 解析过程完成了。</p><p>下图是一个简单的事例：</p><p><img src="/images/b2a6b4950911a95e715154778b1777a4.png" alt=""></p><p>图中的 PlanFrament 包含了一个 ScanNode，ScanNode 扫描 3 个 tablet，每个 tablet 有 2 副本，集群假设有 2 台 host。</p><p>computeScanRangeAssignment 阶段确定了需要扫描 replica 1,3,5,8,10,12，其中 replica 1,3,5 位于 host1 上，replica 8,10,12 位于 host2 上。</p><p>如果全局并发度设置为 1 时，则创建 2 个实例 FInstanceExecParam，下发到 host1 和 host2 上去执行，如果如果全局并发度设置为 3，这个 host1 上创建 3 个实例 FInstanceExecParam，host2 上创建 3 个实例 FInstanceExecParam，每个实例扫描一个 replica，相当于发起 6 个 rpc 请求。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>每一步骤都很重要，然而针对并发度的设置以及不同的文件布局，实际进行调度的时候，会有很多细节，所以mpp架构的数据查询，最有差异的就是这个调度算法以及可以提供的上下文的差异，不同的上下文可以支持的算法是不一样的，这个部分可以多多思考。</p><blockquote><p>注意上边doris的原则</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;doris查询原理&quot;&gt;&lt;a href=&quot;#doris查询原理&quot; class=&quot;headerlink&quot; title=&quot;doris查询原理&quot;&gt;&lt;/a&gt;doris查询原理&lt;/h1&gt;&lt;p&gt;doris的上层mpp部分的查询主要分为四个过程：Analyze，SinglePla</summary>
      
    
    
    
    <category term="大数据" scheme="https://github.com/louzhiqiang/louzhiqiang.github.io.git/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="doris" scheme="https://github.com/louzhiqiang/louzhiqiang.github.io.git/tags/doris/"/>
    
  </entry>
  
  <entry>
    <title>spark优化案例</title>
    <link href="https://github.com/louzhiqiang/louzhiqiang.github.io.git/2022/09/26/spark%E4%BC%98%E5%8C%96%E6%A1%88%E4%BE%8B/"/>
    <id>https://github.com/louzhiqiang/louzhiqiang.github.io.git/2022/09/26/spark%E4%BC%98%E5%8C%96%E6%A1%88%E4%BE%8B/</id>
    <published>2022-09-26T11:01:39.000Z</published>
    <updated>2022-09-26T12:59:18.138Z</updated>
    
    <content type="html"><![CDATA[<h1 id="spark优化案例"><a href="#spark优化案例" class="headerlink" title="spark优化案例"></a>spark优化案例</h1><h2 id="网易基于-Kyuubi-Spark-内核优化以及实践"><a href="#网易基于-Kyuubi-Spark-内核优化以及实践" class="headerlink" title="网易基于 Kyuubi + Spark 内核优化以及实践"></a>网易基于 Kyuubi + Spark 内核优化以及实践</h2><p>一、网易基于AQE的优化。网易有参与到AQE的框架开发中。<br>AQE在spark 2.X就有了初步想法，但是设计简陋，存在很多bug。后来在3.X版本，intel提出了AQE框架：</p><ul><li>对于shuffle reader的优化<ul><li>join倾斜优化</li><li>local shuffle reader    </li></ul></li><li>通过优化执行计划来进一步优化sql的执行性能</li></ul><p>spark 3.2 版本对于AQE是默认开启的。</p><p>AQE 可以解决数据倾斜、小文件、空分区。倾斜的解决方式就是拆开，而小文件的方式就是合并，空分区在小文件这个策略里是可以直接解决掉的。</p><p>AQE可以进行join策略调整，在初始map阶段之后的统计数据，就可以根据这些信息对执行计划做调整。</p><h2 id="kyuubi-spark"><a href="#kyuubi-spark" class="headerlink" title="kyuubi + spark"></a>kyuubi + spark</h2><p>kyuubi对外的作用：</p><ul><li>对外多种接口方式</li><li>多租户</li><li>云原生</li></ul><p>kyuubi分为server 和 engine两个部分，后者已经支持了spark、trino、flink。前者就是集成了多租户以及云原生。</p><p>kyuubi支持了基于proxy类型的long live的行为，这样就可以维护票据问题，也就避免了票据失效的问题。</p><h2 id="对数据质量的优化"><a href="#对数据质量的优化" class="headerlink" title="对数据质量的优化"></a>对数据质量的优化</h2><p>数据质量的两个角度：</p><ul><li>数据压缩率</li><li>数据文件，期望尽量跟hdfs的block契合。</li></ul><p>数据质量好的产出，对于后续的读以及当前数据集合本身的特点，都会有一个比较好的稳定性。</p><p>基于上边kyuubi的方案，有两个优化方向：</p><ul><li>distribute by + local sort<br>存在隐患，比如数据倾斜，因为distribute本身还是会把热键放到一个分区里。<br>local sort对于少数字段的数据影响比较有效果，但是对于多维数据进行local sort，效果会打折扣。</li><li>Rebalance + Z-Order<br>rebalance 在 AQE 框架下提供小文件合并和大文件拆分的功能，而且可以针对写stage做单独的配置，这样针对hdfs的block使用可以尽量利用。<br>Z-Order 本质就是把多维数据可以映射到一维数据，在映射的过程中，可以保证这整个多维数据聚集分布效果不失真。在保证压缩率的前提下，对于后续的data skipping有保障。</li></ul><p>这一套方案对于其他引擎的查询优化是通用的，比如impala、trino等。</p><p><a href="https://appukvkryx45804.pc.xiaoe-tech.com/detail/i_633016dfe4b050af23bc1ede/1?from=p_618dcca0e4b0c005c9902656&fromH5=true&type=6" target="_blank" rel="noopener">方案链接</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;spark优化案例&quot;&gt;&lt;a href=&quot;#spark优化案例&quot; class=&quot;headerlink&quot; title=&quot;spark优化案例&quot;&gt;&lt;/a&gt;spark优化案例&lt;/h1&gt;&lt;h2 id=&quot;网易基于-Kyuubi-Spark-内核优化以及实践&quot;&gt;&lt;a href=&quot;</summary>
      
    
    
    
    <category term="大数据" scheme="https://github.com/louzhiqiang/louzhiqiang.github.io.git/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="spark" scheme="https://github.com/louzhiqiang/louzhiqiang.github.io.git/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>jvm内存结构</title>
    <link href="https://github.com/louzhiqiang/louzhiqiang.github.io.git/2022/09/24/jvm%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84/"/>
    <id>https://github.com/louzhiqiang/louzhiqiang.github.io.git/2022/09/24/jvm%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84/</id>
    <published>2022-09-24T13:09:02.000Z</published>
    <updated>2022-09-24T13:55:45.434Z</updated>
    
    <content type="html"><![CDATA[<h1 id="jvm内存结构"><a href="#jvm内存结构" class="headerlink" title="jvm内存结构"></a>jvm内存结构</h1><p>先看一张图，这张图能很清晰的说明JVM内存结构布局。<br><img src="https://images2015.cnblogs.com/blog/331425/201606/331425-20160623115840235-1252768148.png" alt=""></p><p>JVM内存结构主要有三大块：堆内存、方法区和栈。堆内存是JVM中最大的一块由年轻代和老年代组成，而年轻代内存又被分成三部分，Eden空间、From Survivor空间、To Survivor空间,默认情况下年轻代按照8:1:1的比例来分配；</p><p>方法区存储类信息、常量、静态变量等数据，是线程共享的区域，为与Java堆区分，方法区还有一个别名Non-Heap(非堆)；<br>栈又分为java虚拟机栈和本地方法栈主要用于方法的执行。</p><p><img src="https://images2015.cnblogs.com/blog/331425/201606/331425-20160623115841781-223449019.png" alt=""></p><p>控制参数<br>-Xms设置堆的最小空间大小。<br>-Xmx设置堆的最大空间大小。<br>-XX:NewSize设置新生代最小空间大小。<br>-XX:MaxNewSize设置新生代最大空间大小。<br>-XX:PermSize设置永久代最小空间大小。<br>-XX:MaxPermSize设置永久代最大空间大小。<br>-Xss设置每个线程的堆栈大小。</p><p>老年代空间大小=堆空间大小-年轻代大空间大小</p><p><img src="https://images2015.cnblogs.com/blog/331425/201606/331425-20160623115846235-947282498.png" alt=""></p><p>方法区和堆是所有线程共享的内存区域；而java栈、本地方法栈和程序员计数器是运行是线程私有的内存区域。</p><h2 id="Java堆（Heap）"><a href="#Java堆（Heap）" class="headerlink" title="Java堆（Heap）"></a>Java堆（Heap）</h2><p>堆是jvm占用空间最大的一个，对象都是存储在这个空间。<br>如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError异常。</p><h2 id="方法区（Method-Area）"><a href="#方法区（Method-Area）" class="headerlink" title="方法区（Method Area）"></a>方法区（Method Area）</h2><p>方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。<br>这个区域的内存回收目标主要是针对常量池的回收和对类型的卸载，一般来说这个区域的回收“成绩”比较难以令人满意，尤其是类型的卸载，条件相当苛刻，但是这部分区域的回收确实是有必要的。<br>根据Java虚拟机规范的规定，当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。 </p><h2 id="程序计数器（Program-Counter-Register）"><a href="#程序计数器（Program-Counter-Register）" class="headerlink" title="程序计数器（Program Counter Register）"></a>程序计数器（Program Counter Register）</h2><p>程序计数器（Program Counter Register）是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里（仅是概念模型，各种虚拟机可能会通过一些更高效的方式去实现），字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。<br>由于Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，<strong>每条线程都需要有一个独立的程序计数器</strong>，各条线程之间的计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。</p><p>如果线程正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Natvie方法，这个计数器值则为空（Undefined）。</p><p>此内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。</p><h2 id="JVM栈（JVM-Stacks）"><a href="#JVM栈（JVM-Stacks）" class="headerlink" title="JVM栈（JVM Stacks）"></a>JVM栈（JVM Stacks）</h2><p>与程序计数器一样，Java虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，它的生命周期与线程相同。<strong>虚拟机栈描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。</strong>每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 </p><p>局部变量表存放了编译期可知的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型，它不等同于对象本身，根据不同的虚拟机实现，它可能是一个指向对象起始地址的引用指针，也可能指向一个代表对象的句柄或者其他与此对象相关的位置）和returnAddress类型（指向了一条字节码指令的地址）。</p><p>其中64位长度的long和double类型的数据会占用2个局部变量空间（Slot），其余的数据类型只占用1个。局部变量表所需的内存空间在编译期间完成分配，<strong>当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小</strong>。</p><p>在Java虚拟机规范中，对这个区域规定了两种异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出<strong>StackOverflowError异常</strong>；如果虚拟机栈可以动态扩展（当前大部分的Java虚拟机都可动态扩展，只不过Java虚拟机规范中也允许固定长度的虚拟机栈），当扩展时无法申请到足够的内存时会抛出<strong>OutOfMemoryError异常</strong>。</p><h2 id="本地方法栈（Native-Method-Stacks）"><a href="#本地方法栈（Native-Method-Stacks）" class="headerlink" title="本地方法栈（Native Method Stacks）"></a>本地方法栈（Native Method Stacks）</h2><p>本地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的<strong>Native方法</strong>服务。虚拟机规范中对本地方法栈中的方法使用的语言、使用方式与数据结构并没有强制规定，因此具体的虚拟机可以自由实现它。甚至有的虚拟机（譬如Sun HotSpot虚拟机）直接就把本地方法栈和虚拟机栈合二为一。与虚拟机栈一样，本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;jvm内存结构&quot;&gt;&lt;a href=&quot;#jvm内存结构&quot; class=&quot;headerlink&quot; title=&quot;jvm内存结构&quot;&gt;&lt;/a&gt;jvm内存结构&lt;/h1&gt;&lt;p&gt;先看一张图，这张图能很清晰的说明JVM内存结构布局。&lt;br&gt;&lt;img src=&quot;https://im</summary>
      
    
    
    
    <category term="java" scheme="https://github.com/louzhiqiang/louzhiqiang.github.io.git/categories/java/"/>
    
    
  </entry>
  
  <entry>
    <title>Java中用户线程和守护线程</title>
    <link href="https://github.com/louzhiqiang/louzhiqiang.github.io.git/2022/09/24/Java%E4%B8%AD%E7%94%A8%E6%88%B7%E7%BA%BF%E7%A8%8B%E5%92%8C%E5%AE%88%E6%8A%A4%E7%BA%BF%E7%A8%8B/"/>
    <id>https://github.com/louzhiqiang/louzhiqiang.github.io.git/2022/09/24/Java%E4%B8%AD%E7%94%A8%E6%88%B7%E7%BA%BF%E7%A8%8B%E5%92%8C%E5%AE%88%E6%8A%A4%E7%BA%BF%E7%A8%8B/</id>
    <published>2022-09-24T07:38:19.000Z</published>
    <updated>2022-09-24T07:49:32.174Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Java中用户线程和守护线程"><a href="#Java中用户线程和守护线程" class="headerlink" title="Java中用户线程和守护线程"></a>Java中用户线程和守护线程</h1><p>Java 语言中无论是线程还是线程池，默认都是用户线程，因此用户线程也被成为普通线程。</p><p>以线程为例，想要查看线程是否为守护线程只需通过调用 isDaemon() 方法查询即可，如果查询的值为 false 则表示不为守护线程，自然也就属于用户线程了.</p><p>守护线程（Daemon Thread）也被称之为后台线程或服务线程，守护线程是为用户线程服务的，当程序中的用户线程全部执行结束之后，守护线程也会跟随结束。</p><h2 id="两者的区别"><a href="#两者的区别" class="headerlink" title="两者的区别"></a>两者的区别</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DaemonExample</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        Thread thread = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= <span class="number">10</span>; i++) &#123;</span><br><span class="line">                    <span class="comment">// 打印 i 信息</span></span><br><span class="line">                    System.out.println(<span class="string">"i:"</span> + i);</span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        <span class="comment">// 休眠 100 毫秒</span></span><br><span class="line">                        Thread.sleep(<span class="number">100</span>);</span><br><span class="line">                    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="comment">// 设置为守护线程</span></span><br><span class="line">        thread.setDaemon(<span class="keyword">true</span>);</span><br><span class="line">        <span class="comment">// 启动线程</span></span><br><span class="line">        thread.start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/950cff9bc03748599bcc418f8252e15c~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp" alt=""></p><p>可见守护线程在用户线程执行完毕也就直接销毁了，所以后续的打印就没有执行。</p><p>守护线程的使用需要注意以下三个问题：</p><ol><li>守护线程的设置 setDaemon(true) 必须要放在线程的 start() 之前，否则程序会报错。</li><li>在守护线程中创建的所有子线程都是守护线程。</li><li>使用 jojn() 方法会等待一个线程执行完，无论此线程是用户线程还是守护线程。</li></ol><h2 id="守护线程应用场景"><a href="#守护线程应用场景" class="headerlink" title="守护线程应用场景"></a>守护线程应用场景</h2><p><strong>守护线程的典型应用场景就是垃圾回收线程</strong>，当然还有一些场景也非常适合使用守护线程，比如服务器端的健康检测功能，对于一个服务器来说健康检测功能属于非核心非主流的服务业务，像这种为了主要业务服务的业务功能就非常合适使用守护线程，当程序中的主要业务都执行完成之后，服务业务也会跟随者一起销毁。</p><p>守护线程从业务逻辑层面来看权重比较低，但对于线程调度器来说无论是守护线程还是用户线程，在优先级相同的情况下被执行的概率都是相同的。守护线程的经典使用场景是垃圾回收线程，守护线程中创建的线程默认情况下也都是守护线程。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Java中用户线程和守护线程&quot;&gt;&lt;a href=&quot;#Java中用户线程和守护线程&quot; class=&quot;headerlink&quot; title=&quot;Java中用户线程和守护线程&quot;&gt;&lt;/a&gt;Java中用户线程和守护线程&lt;/h1&gt;&lt;p&gt;Java 语言中无论是线程还是线程池，默认都</summary>
      
    
    
    
    <category term="java" scheme="https://github.com/louzhiqiang/louzhiqiang.github.io.git/categories/java/"/>
    
    
  </entry>
  
  <entry>
    <title>java锁粗化、锁消除、锁膨胀、自适应自旋锁</title>
    <link href="https://github.com/louzhiqiang/louzhiqiang.github.io.git/2022/09/24/java%E9%94%81%E7%B2%97%E5%8C%96%E3%80%81%E9%94%81%E6%B6%88%E9%99%A4%E3%80%81%E9%94%81%E8%86%A8%E8%83%80%E3%80%81%E8%87%AA%E9%80%82%E5%BA%94%E8%87%AA%E6%97%8B%E9%94%81/"/>
    <id>https://github.com/louzhiqiang/louzhiqiang.github.io.git/2022/09/24/java%E9%94%81%E7%B2%97%E5%8C%96%E3%80%81%E9%94%81%E6%B6%88%E9%99%A4%E3%80%81%E9%94%81%E8%86%A8%E8%83%80%E3%80%81%E8%87%AA%E9%80%82%E5%BA%94%E8%87%AA%E6%97%8B%E9%94%81/</id>
    <published>2022-09-24T03:18:47.000Z</published>
    <updated>2022-09-24T07:38:29.693Z</updated>
    
    <content type="html"><![CDATA[<h1 id="java锁粗化、锁消除、锁膨胀、自适应自旋锁"><a href="#java锁粗化、锁消除、锁膨胀、自适应自旋锁" class="headerlink" title="java锁粗化、锁消除、锁膨胀、自适应自旋锁"></a>java锁粗化、锁消除、锁膨胀、自适应自旋锁</h1><p>java在1.6版本中对于关键字 synchronized 进行了深度优化，主要优化以下四个特性：</p><ol><li>锁膨胀</li><li>锁消除</li><li>锁粗化</li><li>自适应自旋锁</li></ol><h2 id="锁膨胀"><a href="#锁膨胀" class="headerlink" title="锁膨胀"></a>锁膨胀</h2><p>所谓的锁膨胀是指 synchronized 从无锁升级到偏向锁，再到轻量级锁，最后到重量级锁的过程，它叫做锁膨胀也叫做锁升级。<br>JDK 1.6 之前，synchronized 是重量级锁，也就是说 synchronized 在释放和获取锁时都会从用户态转换成内核态，而转换的效率是比较低的。但有了锁膨胀机制之后，synchronized 的状态就多了无锁、偏向锁以及轻量级锁了，这时候在进行并发操作时，大部分的场景都不需要用户态到内核态的转换了，这样就大幅的提升了 synchronized 的性能。</p><h2 id="锁消除"><a href="#锁消除" class="headerlink" title="锁消除"></a>锁消除</h2><p>锁消除指的是在某些情况下，JVM 虚拟机如果检测不到某段代码被共享和竞争的可能性，就会将这段代码所属的同步锁消除掉，从而提高程序性能的目的。<br>锁消除的依据是逃逸分析的数据支持，如 StringBuffer 的 append() 方法，或 Vector 的 add() 方法，在很多情况下是可以进行锁消除的，比如以下这段代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">method</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    StringBuffer sb = <span class="keyword">new</span> StringBuffer();</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">        sb.append(<span class="string">"i:"</span> + i);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> sb.toString();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://cdn.nlark.com/yuque/0/2021/png/92791/1628004235900-ceda983f-f425-4d47-8dae-6cc7e193b882.png#align=left&display=inline&height=523&id=ua61627da&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1046&originWidth=2120&size=217934&status=done&style=none&width=1060" alt=""></p><blockquote><p>stringBuilder是非线程安全的。stringBuffer是线程安全的。</p></blockquote><p>从上述结果可以看出，之前我们写的线程安全的加锁的 StringBuffer 对象，在生成字节码之后就被替换成了不加锁不安全的 StringBuilder 对象了，原因是 <strong>StringBuffer 的变量属于一个局部变量，并且不会从该方法中逃逸出去，所以此时我们就可以使用锁消除（不加锁）来加速程序的运行</strong>。</p><h2 id="锁粗化"><a href="#锁粗化" class="headerlink" title="锁粗化"></a>锁粗化</h2><p>锁粗化是指，将多个连续的加锁、解锁操作连接在一起，扩展成一个范围更大的锁。<br>我只听说锁“细化”可以提高程序的执行效率，也就是将锁的范围尽可能缩小，这样在锁竞争时，等待获取锁的线程才能更早的获取锁，从而提高程序的运行效率，但锁粗化是如何提高性能的呢？</p><p>没错，锁细化的观点在大多数情况下都是成立了，但是一系列连续加锁和解锁的操作，也会导致不必要的性能开销，从而影响程序的执行效率，比如这段代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">method</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    StringBuilder sb = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">        <span class="comment">// 伪代码：加锁操作</span></span><br><span class="line">        sb.append(<span class="string">"i:"</span> + i);</span><br><span class="line">        <span class="comment">// 伪代码：解锁操作</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> sb.toString();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里我们不考虑编译器优化的情况，如果在 for 循环中定义锁，那么锁的范围很小，但每次 for 循环都需要进行加锁和释放锁的操作，性能是很低的；但如果我们直接在 for 循环的外层加一把锁，那么对于同一个对象操作这段代码的性能就会提高很多，如下伪代码所示：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">method</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    StringBuilder sb = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">    <span class="comment">// 伪代码：加锁操作</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">        sb.append(<span class="string">"i:"</span> + i);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 伪代码：解锁操作</span></span><br><span class="line">    <span class="keyword">return</span> sb.toString();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>锁粗化的作用：<strong>如果检测到同一个对象执行了连续的加锁和解锁的操作，则会将这一系列操作合并成一个更大的锁，从而提升程序的执行效率</strong>。</p><h2 id="自适应自旋锁"><a href="#自适应自旋锁" class="headerlink" title="自适应自旋锁"></a>自适应自旋锁</h2><p>自旋锁是指通过自身循环，尝试获取锁的一种方式，伪代码实现如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 尝试获取锁</span></span><br><span class="line"><span class="keyword">while</span>(!isLock())&#123;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>自旋锁优点在于它避免一些线程的挂起和恢复操作，因为挂起线程和恢复线程都需要从用户态转入内核态，这个过程是比较慢的，所以通过自旋的方式可以一定程度上避免线程挂起和恢复所造成的性能开销。</strong><br>但是，如果长时间自旋还获取不到锁，那么也会造成一定的资源浪费，所以我们通常会给自旋设置一个固定的值来避免一直自旋的性能开销。然而对于 synchronized 关键字来说，它的自旋锁更加的“智能”，synchronized 中的自旋锁是自适应自旋锁，这就好比之前一直开的手动挡的三轮车，而经过了 JDK 1.6 的优化之后，我们的这部“车”，一下子变成自动挡的兰博基尼了。</p><p>自适应自旋锁是指，<strong>线程自旋的次数不再是固定的值，而是一个动态改变的值，这个值会根据前一次自旋获取锁的状态来决定此次自旋的次数</strong>。比如上一次通过自旋成功获取到了锁，那么这次通过自旋也有可能会获取到锁，所以这次自旋的次数就会增多一些，而如果上一次通过自旋没有成功获取到锁，那么这次自旋可能也获取不到锁，所以为了避免资源的浪费，就会少循环或者不循环，以提高程序的执行效率。简单来说，<strong>如果线程自旋成功了，则下次自旋的次数会增多，如果失败，下次自旋的次数会减少</strong>。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;java锁粗化、锁消除、锁膨胀、自适应自旋锁&quot;&gt;&lt;a href=&quot;#java锁粗化、锁消除、锁膨胀、自适应自旋锁&quot; class=&quot;headerlink&quot; title=&quot;java锁粗化、锁消除、锁膨胀、自适应自旋锁&quot;&gt;&lt;/a&gt;java锁粗化、锁消除、锁膨胀、自适应自</summary>
      
    
    
    
    <category term="java" scheme="https://github.com/louzhiqiang/louzhiqiang.github.io.git/categories/java/"/>
    
    
  </entry>
  
  <entry>
    <title>spark共享变量</title>
    <link href="https://github.com/louzhiqiang/louzhiqiang.github.io.git/2022/09/24/spark%E5%85%B1%E4%BA%AB%E5%8F%98%E9%87%8F/"/>
    <id>https://github.com/louzhiqiang/louzhiqiang.github.io.git/2022/09/24/spark%E5%85%B1%E4%BA%AB%E5%8F%98%E9%87%8F/</id>
    <published>2022-09-24T03:06:26.000Z</published>
    <updated>2022-09-26T12:59:28.618Z</updated>
    
    <content type="html"><![CDATA[<h1 id="spark共享变量"><a href="#spark共享变量" class="headerlink" title="spark共享变量"></a>spark共享变量</h1><p>spark有两大共享变量：广播变量和累加器</p><p>累加器用来对信息进行聚合，而广播变量用来高效分发较大的对象。</p><h2 id="共享变量"><a href="#共享变量" class="headerlink" title="共享变量"></a>共享变量</h2><p>共享变量出现的原因：<br>通常在向 Spark 传递函数时，比如使用 map() 函数或者用 filter() 传条件时，可以使用驱动器程序中定义的变量，但是集群中运行的每个任务都会得到这些变量的一份新的副本，更新这些副本的值也不会影响驱动器中的对应变量。Spark 的两个共享变量，累加器与广播变量，分别为结果聚合与广播这两种常见的通信模式突破了这一限制。</p><p>Spark 会自动把闭包中所有引用到的变量发送到工作节点上。虽然这很方便，但也很低效。原因有二：首先，默认的任务发射机制是专门为小任务进行优化的；其次，事实上你可能会在多个并行操作中使用同一个变量，但是 Spark 会为每个操作分别发送。</p><p><img src="https://img-blog.csdn.net/20180401185652753?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FuZHJvaWRfeHVl/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></p><p>list是在driver端创建的，但是因为需要在excutor端使用，所以driver会把list以task的形式发送到excutor端，如果有很多个task，就会有很多给excutor端携带很多个list，如果这个list非常大的时候，就可能会造成内存溢出（如下图所示）。这个时候就引出了广播变量。</p><p><img src="https://img-blog.csdn.net/20180401185706513?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FuZHJvaWRfeHVl/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></p><p>使用广播变量后：</p><p><img src="https://img-blog.csdn.net/20180401185715750?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FuZHJvaWRfeHVl/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></p><p>使用广播变量的过程很简单：<br>(1) 通过对一个类型 T 的对象调用 SparkContext.broadcast 创建出一个 Broadcast[T] 对象。任何可序列化的类型都可以这么实现。<br>(2) 通过 value 属性访问该对象的值（在 Java 中为 value() 方法）。<br>(3) 变量只会被发到各个节点一次，应作为只读值处理（修改这个值不会影响到别的节点）。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">BroadcastTest</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local"</span>).setAppName(<span class="string">"broadcast"</span>)</span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    <span class="keyword">val</span> list = <span class="type">List</span>(<span class="string">"hello java"</span>)</span><br><span class="line">    <span class="keyword">val</span> broadcast = sc.broadcast(list)</span><br><span class="line">    <span class="keyword">val</span> linesRDD = sc.textFile(<span class="string">"./word"</span>)</span><br><span class="line">    linesRDD.filter(line =&gt; &#123;</span><br><span class="line">      broadcast.value.contains(line)</span><br><span class="line">    &#125;).foreach(println)</span><br><span class="line">    sc.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>广播变量只在driver端定义，不能在executor端定义。也不能在executor端进行更改。</p></blockquote><h2 id="累加器"><a href="#累加器" class="headerlink" title="累加器"></a>累加器</h2><p>依然是driver和excutor端的数据不能共享的问题。excutor端修改了变量，根本不会让driver端跟着修改，这个就是累加器出现的原因。</p><p>累加器的作用：<br>提供了将工作节点中的值聚合到驱动器程序中的简单语法。</p><p>常用场景：<br>调试时对作业执行过程中的事件进行计数。</p><p><img src="https://img-blog.csdn.net/20180401185950994?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FuZHJvaWRfeHVl/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></p><p> 累加器的用法如下所示：<br>(1)通过在driver中调用 SparkContext.accumulator(initialValue) 方法，创建出存有初始值的累加器。返回值为 org.apache.spark.Accumulator[T] 对象，其中 T 是初始值initialValue 的类型。<br>(2)Spark闭包（函数序列化）里的excutor代码可以使用累加器的 += 方法（在Java中是 add ）增加累加器的值。<br>(3)driver程序可以调用累加器的 value 属性（在 Java 中使用 value() 或 setValue() ）来访问累加器的值。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">AccumulatorTest</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local"</span>).setAppName(<span class="string">"accumulator"</span>)</span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    <span class="keyword">val</span> accumulator = sc.accumulator(<span class="number">0</span>); <span class="comment">//创建accumulator并初始化为0</span></span><br><span class="line">    <span class="keyword">val</span> linesRDD = sc.textFile(<span class="string">"./word"</span>)</span><br><span class="line">    <span class="keyword">val</span> result = linesRDD.map(s =&gt; &#123;</span><br><span class="line">      accumulator.add(<span class="number">1</span>) <span class="comment">//有一条数据就增加1s</span></span><br><span class="line">    &#125;)</span><br><span class="line">    result.collect();</span><br><span class="line">    println(<span class="string">"words lines is :"</span> + accumulator.value)</span><br><span class="line">    sc.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>累加器在Driver端定义赋初始值，累加器只能在Driver端读取，在Excutor端更新.</p></blockquote><p><img src="https://img-blog.csdn.net/20180401190109965?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FuZHJvaWRfeHVl/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;spark共享变量&quot;&gt;&lt;a href=&quot;#spark共享变量&quot; class=&quot;headerlink&quot; title=&quot;spark共享变量&quot;&gt;&lt;/a&gt;spark共享变量&lt;/h1&gt;&lt;p&gt;spark有两大共享变量：广播变量和累加器&lt;/p&gt;
&lt;p&gt;累加器用来对信息进行聚合，</summary>
      
    
    
    
    <category term="大数据" scheme="https://github.com/louzhiqiang/louzhiqiang.github.io.git/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="spark" scheme="https://github.com/louzhiqiang/louzhiqiang.github.io.git/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>ConcurrentHashMap原理</title>
    <link href="https://github.com/louzhiqiang/louzhiqiang.github.io.git/2022/09/23/ConcurrentHashMap%E5%8E%9F%E7%90%86/"/>
    <id>https://github.com/louzhiqiang/louzhiqiang.github.io.git/2022/09/23/ConcurrentHashMap%E5%8E%9F%E7%90%86/</id>
    <published>2022-09-23T13:00:35.000Z</published>
    <updated>2022-09-23T14:12:34.215Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ConcurrentHashMap原理"><a href="#ConcurrentHashMap原理" class="headerlink" title="ConcurrentHashMap原理"></a>ConcurrentHashMap原理</h1><h2 id="ConcurrentHashMap和HashMap以及Hashtable的区别"><a href="#ConcurrentHashMap和HashMap以及Hashtable的区别" class="headerlink" title="ConcurrentHashMap和HashMap以及Hashtable的区别"></a>ConcurrentHashMap和HashMap以及Hashtable的区别</h2><ul><li>HashMap是线程不安全的，因为HashMap中操作都没有加锁，因此在多线程环境下会导致数据覆盖之类的问题，所以，在多线程中使用HashMap是会抛出异常的。</li><li>HashTable是线程安全的,但是HashTable只是单纯的在put()方法上加上synchronized。保证插入时阻塞其他线程的插入操作。虽然安全，但因为设计简单，所以性能低下。</li><li>ConcurrentHashMap是线程安全的，ConcurrentHashMap并非锁住整个方法，而是通过原子操作和局部加锁的方法保证了多线程的线程安全，且尽可能减少了性能损耗。</li></ul><h2 id="ConcurrentHashMap原理-1"><a href="#ConcurrentHashMap原理-1" class="headerlink" title="ConcurrentHashMap原理"></a>ConcurrentHashMap原理</h2><p>它由多个 Segment 组合而成。Segment 本身就相当于一个 HashMap 对象。同 HashMap 一样，Segment 包含一个 HashEntry 数组，数组中的每一个 HashEntry 既是一个键值对，也是一个链表的头节点。<br><img src="https://img-blog.csdnimg.cn/20200807200052113.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI5MDUxNDEz,size_16,color_FFFFFF,t_70" alt=""></p><p>像这样的 Segment 对象，在 ConcurrentHashMap 集合中有多少个呢？有 2 的 N 次方个，共同保存在一个名为 segments 的数组当中。</p><p><img src="https://img-blog.csdnimg.cn/20200807200123141.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI5MDUxNDEz,size_16,color_FFFFFF,t_70" alt=""></p><p>可以说，ConcurrentHashMap 是一个二级哈希表。在一个总的哈希表下面，有若干个子哈希表。</p><p><img src="https://img-blog.csdnimg.cn/20200807201722260.png" alt=""></p><p>其中，Segment是它的一个内部类，主要组成如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">Segment</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">ReentrantLock</span> <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">2249069246763182397L</span>;</span><br><span class="line"><span class="comment">// 和 HashMap 中的 HashEntry 作用一样，真正存放数据的桶</span></span><br><span class="line"><span class="keyword">transient</span> <span class="keyword">volatile</span> HashEntry&lt;K,V&gt;[] table;</span><br><span class="line"></span><br><span class="line"><span class="keyword">transient</span> <span class="keyword">int</span> count;</span><br><span class="line"><span class="keyword">transient</span> <span class="keyword">int</span> modCount;</span><br><span class="line"><span class="keyword">transient</span> <span class="keyword">int</span> threshold;</span><br><span class="line"><span class="keyword">final</span> <span class="keyword">float</span> loadFactor;</span><br><span class="line"></span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>HashEntry也是一个内部类，主要组成如下：<br><img src="https://img-blog.csdnimg.cn/20200807202323615.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI5MDUxNDEz,size_16,color_FFFFFF,t_70" alt=""><br>和 HashMap 的 Entry 基本一样，唯一的区别就是其中的核心数据如 value ，以及<strong>链表都是 volatile 修饰的，保证了获取时的可见性</strong>。</p><p>基于volatile修饰之后，数据获取效率是很高的。</p><h3 id="Put-操作"><a href="#Put-操作" class="headerlink" title="Put 操作"></a>Put 操作</h3><p><img src="https://img-blog.csdnimg.cn/20200807202542921.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI5MDUxNDEz,size_16,color_FFFFFF,t_70" alt=""></p><p>首先是通过 key 定位到 Segment，之后在对应的 Segment 中进行具体的 put。<br><img src="https://img-blog.csdnimg.cn/20200807202759568.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI5MDUxNDEz,size_16,color_FFFFFF,t_70" alt=""></p><p>这个put就是针对Segment的。<br>虽然 HashEntry 中的 value 是用 volatile 关键词修饰的，但是并不能保证并发的原子性，所以 put 操作时仍然需要加锁处理。</p><p><img src="https://img-blog.csdnimg.cn/20200807203115482.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI5MDUxNDEz,size_16,color_FFFFFF,t_70" alt=""></p><p>1、尝试自旋获取锁。<br>2、如果重试的次数达到了 MAX_SCAN_RETRIES 则改为阻塞锁获取，保证能获取成功。</p><p><img src="https://img-blog.csdnimg.cn/20200807203318514.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI5MDUxNDEz,size_16,color_FFFFFF,t_70" alt=""></p><p>1、加锁操作；<br>2、遍历该 HashEntry，如果不为空则判断传入的 key 和当前遍历的 key 是否相等，相等则覆盖旧的 value。<br>3、为空则需要新建一个 HashEntry 并加入到 Segment 中，同时会先判断是否需要扩容。<br>4、释放锁；</p><p>Put 操作时，锁的是某个 Segment，其他线程对其他 Segment 的读写操作均不影响。因此解决了线程安全问题。</p><h3 id="Get-操作"><a href="#Get-操作" class="headerlink" title="Get 操作"></a>Get 操作</h3><p><img src="https://img-blog.csdnimg.cn/20200807203606205.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI5MDUxNDEz,size_16,color_FFFFFF,t_70" alt=""></p><p>1、Key 通过 Hash 之后定位到具体的 Segment；<br>2、再通过一次 Hash 定位到具体的元素上；<br>3、由于 HashEntry 中的 value 属性是用 volatile 关键词修饰的，保证了内存可见性，所以每次获取时都是最新值。</p><h2 id="JDK-1-8-的改进"><a href="#JDK-1-8-的改进" class="headerlink" title="JDK 1.8 的改进"></a>JDK 1.8 的改进</h2><ul><li>首先是结构上的变化，和 HashMap 一样，数组+链表改为数组+链表+红黑树。</li><li>HashEntry 改为 Node</li><li>Put 操作的变化<br><img src="https://img-blog.csdnimg.cn/2020080720541110.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI5MDUxNDEz,size_16,color_FFFFFF,t_70" alt=""><br>1、根据 key 计算出 hashcode，然后开始遍历 table；<br>2、判断是否需要初始化；<br>3、f 即为当前 key 定位出的 Node，如果为空表示当前位置可以写入数据，利用 CAS 尝试写入，失败则自旋保证成功。<br>4、如果当前位置的 hashcode == MOVED == -1,则需要进行扩容。<br>5、如果都不满足，则利用 synchronized 锁写入数据。<br>6、如果数量大于 TREEIFY_THRESHOLD 则要转换为红黑树。</li><li>Get 操作的变化<br><img src="https://img-blog.csdnimg.cn/20200807205906631.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI5MDUxNDEz,size_16,color_FFFFFF,t_70" alt=""><br>1、根据计算出来的 hashcode 寻址，如果就在桶上那么直接返回值。<br>2、如果是红黑树那就按照树的方式获取值。<br>3、都不满足那就按照链表的方式遍历获取值。</li></ul><blockquote><p>1.8 在 1.7 的数据结构上做了大的改动，采用红黑树之后可以保证查询效率（O(logn)），甚至取消了 ReentrantLock 改为了 synchronized，这样可以看出在新版的 JDK 中对 synchronized 优化是很到位的。</p></blockquote><p>参考：<br><a href="https://blog.csdn.net/qq_42068856/article/details/126091526" target="_blank" rel="noopener">1.8版本ConcurrentHashMap的put原理</a></p><h2 id="面试常问的"><a href="#面试常问的" class="headerlink" title="面试常问的"></a>面试常问的</h2><h3 id="1-7-版本和-1-8-版本有啥区别，关于ConcurrentHashMap"><a href="#1-7-版本和-1-8-版本有啥区别，关于ConcurrentHashMap" class="headerlink" title="1.7 版本和 1.8 版本有啥区别，关于ConcurrentHashMap"></a>1.7 版本和 1.8 版本有啥区别，关于ConcurrentHashMap</h3><h4 id="1-7"><a href="#1-7" class="headerlink" title="1.7"></a>1.7</h4><p>JDK1.7 中的 ConcurrentHashMap 是由 Segment 数组结构和 HashEntry 数组结构组成，即 ConcurrentHashMap 把哈希桶数组切分成小数组（Segment ），每个小数组有 n 个 HashEntry 组成。</p><p>如下图所示，首先将数据分为一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一段数据时，其他段的数据也能被其他线程访问，实现了真正的并发访问。<br><img src="https://img-blog.csdnimg.cn/img_convert/8bf6d4aa717a871c73d5d2699d822fed.png" alt=""></p><p>Segment 是 ConcurrentHashMap 的一个内部类，主要的组成如下：<br><img src="https://img-blog.csdnimg.cn/img_convert/892f684f7d943d1194b290b5f414d558.png" alt=""></p><p>Segment 继承了 ReentrantLock，所以 Segment 是一种可重入锁，扮演锁的角色。Segment 默认为 16，也就是并发度为 16。</p><p>存放元素的 HashEntry，也是一个静态内部类，主要的组成如下：<br><img src="https://img-blog.csdnimg.cn/img_convert/d41507b8e7a653650561367d44e5411d.png" alt=""></p><p>其中，用 volatile 修饰了 HashEntry 的数据 value 和 下一个节点 next，保证了多线程环境下数据获取时的可见性！</p><h4 id="1-8"><a href="#1-8" class="headerlink" title="1.8"></a>1.8</h4><p>JDK1.8 中的ConcurrentHashMap 选择了与 HashMap 相同的Node数组+链表+红黑树结构；在锁的实现上，抛弃了原有的 Segment 分段锁，采用CAS + synchronized实现更加细粒度的锁。<br>将锁的级别控制在了更细粒度的<strong>哈希桶数组元素级别</strong>，也就是说只需要锁住这个链表头节点（红黑树的根节点），就不会影响其他的哈希桶数组元素的读写，大大提高了并发度。<br><img src="https://img-blog.csdnimg.cn/img_convert/3e0ef497f95c88e6d409cd6f0737bfe3.png" alt=""></p><h3 id="JDK1-8-中为什么使用内置锁-synchronized替换-可重入锁-ReentrantLock？"><a href="#JDK1-8-中为什么使用内置锁-synchronized替换-可重入锁-ReentrantLock？" class="headerlink" title="JDK1.8 中为什么使用内置锁 synchronized替换 可重入锁 ReentrantLock？"></a>JDK1.8 中为什么使用内置锁 synchronized替换 可重入锁 ReentrantLock？</h3><ul><li>1.6版本针对synchronized进行了优化，他的效率高了很多。</li><li>减少内存开销 。假设使用可重入锁来获得同步支持，那么每个节点都需要通过继承 AQS 来获得同步支持。但并不是每个节点都需要获得同步支持的，只有<strong>链表的头节点（红黑树的根节点）需要同步</strong>，这无疑带来了巨大内存浪费。</li></ul><h3 id="ConcurrentHashMap-的-put-方法执行逻辑是什么？"><a href="#ConcurrentHashMap-的-put-方法执行逻辑是什么？" class="headerlink" title="ConcurrentHashMap 的 put 方法执行逻辑是什么？"></a>ConcurrentHashMap 的 put 方法执行逻辑是什么？</h3><h4 id="JDK1-7"><a href="#JDK1-7" class="headerlink" title="JDK1.7"></a>JDK1.7</h4><p><img src="https://img-blog.csdnimg.cn/img_convert/d74b564ac361f2b01f314198eb5dc8ea.png" alt=""><br>先定位到相应的 Segment ，然后再进行 put 操作。<br><img src="https://img-blog.csdnimg.cn/img_convert/76cc8ca680a660a3a04b65b29801cb0b.png" alt=""><br>首先会尝试获取锁，如果获取失败肯定就有其他线程存在竞争，则利用 scanAndLockForPut() 自旋获取锁。</p><ul><li>尝试自旋获取锁。</li><li>如果重试的次数达到了 MAX_SCAN_RETRIES 则改为阻塞锁获取，保证能获取成功。</li></ul><h4 id="JDK1-8"><a href="#JDK1-8" class="headerlink" title="JDK1.8"></a>JDK1.8</h4><ul><li>根据 key 计算出 hash 值；</li><li>判断是否需要进行初始化；</li><li>定位到 Node，拿到首节点 f，判断首节点 f：<ul><li>如果为 null ，则通过 CAS 的方式尝试添加；</li><li>如果为 f.hash = MOVED = -1 ，说明其他线程在扩容，参与一起扩容；</li><li>如果都不满足 ，synchronized 锁住 f 节点，判断是链表还是红黑树，遍历插入；</li><li>当在链表长度达到 8 的时候，数组扩容或者将链表转换为红黑树。<br><img src="https://img-blog.csdnimg.cn/img_convert/d2eb3182bc96169e2f29c6df38f92891.png" alt=""></li></ul></li></ul><h3 id="ConcurrentHashMap-的-get-方法执行逻辑是什么？"><a href="#ConcurrentHashMap-的-get-方法执行逻辑是什么？" class="headerlink" title="ConcurrentHashMap 的 get 方法执行逻辑是什么？"></a>ConcurrentHashMap 的 get 方法执行逻辑是什么？</h3><h4 id="JDK1-7-1"><a href="#JDK1-7-1" class="headerlink" title="JDK1.7"></a>JDK1.7</h4><p>首先，根据 key 计算出 hash 值定位到具体的 Segment ，再根据 hash 值获取定位 HashEntry 对象，并对 HashEntry 对象进行链表遍历，找到对应元素。</p><p>由于 HashEntry 涉及到的共享变量都使用 volatile 修饰，volatile 可以保证内存可见性，所以每次获取时都是最新值。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/19e8e13c0fc91718739fbc3388c9797f.png" alt=""></p><h4 id="JDK1-8-1"><a href="#JDK1-8-1" class="headerlink" title="JDK1.8"></a>JDK1.8</h4><ul><li>根据 key 计算出 hash 值，判断数组是否为空；</li><li>如果是首节点，就直接返回；</li><li>如果是红黑树结构，就从红黑树里面查询；</li><li>如果是链表结构，循环遍历判断。<br><img src="https://img-blog.csdnimg.cn/img_convert/753d017dc01e3096673800357165e067.png" alt=""></li></ul><h3 id="ConcurrentHashMap-的-get-方法是否要加锁，为什么？"><a href="#ConcurrentHashMap-的-get-方法是否要加锁，为什么？" class="headerlink" title="ConcurrentHashMap 的 get 方法是否要加锁，为什么？"></a>ConcurrentHashMap 的 get 方法是否要加锁，为什么？</h3><p>get 方法不需要加锁。因为 Node 的元素 value 和指针 next 是用 volatile 修饰的，在多线程环境下线程A修改节点的 value 或者新增节点的时候是对线程B可见的。<br>这也是它比其他并发集合比如 Hashtable、用 Collections.synchronizedMap()包装的 HashMap 效率高的原因之一。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/7c1ca4b6190fe58a20f586164d017851.png" alt=""></p><h3 id="get-方法不需要加锁与-volatile-修饰的哈希桶数组有关吗？"><a href="#get-方法不需要加锁与-volatile-修饰的哈希桶数组有关吗？" class="headerlink" title="get 方法不需要加锁与 volatile 修饰的哈希桶数组有关吗？"></a>get 方法不需要加锁与 volatile 修饰的哈希桶数组有关吗？</h3><p>没有关系。哈希桶数组table用 volatile 修饰主要是保证在数组扩容的时候保证可见性。<br><img src="https://img-blog.csdnimg.cn/img_convert/3f10cd575e3750a4e384f71fd7adc3cc.png" alt=""></p><h3 id="ConcurrentHashMap-不支持-key-或者-value-为-null-的原因？"><a href="#ConcurrentHashMap-不支持-key-或者-value-为-null-的原因？" class="headerlink" title="ConcurrentHashMap 不支持 key 或者 value 为 null 的原因？"></a>ConcurrentHashMap 不支持 key 或者 value 为 null 的原因？</h3><p>我们先来说value 为什么不能为 null。因为 ConcurrentHashMap 是用于多线程的 ，如果ConcurrentHashMap.get(key)得到了 null ，这就无法判断，是映射的value是 null ，还是没有找到对应的key而为 null ，就有了<strong>二义性</strong>。</p><p>而用于单线程状态的 HashMap 却可以用<strong>containsKey(key)</strong> 去判断到底是否包含了这个 null 。</p><h3 id="ConcurrentHashMap-的并发度是什么？"><a href="#ConcurrentHashMap-的并发度是什么？" class="headerlink" title="ConcurrentHashMap 的并发度是什么？"></a>ConcurrentHashMap 的并发度是什么？</h3><p>并发度可以理解为程序运行时能够同时更新 ConccurentHashMap且不产生锁竞争的最大线程数。在JDK1.7中，实际上就是ConcurrentHashMap中的分段锁个数，即Segment[]的数组长度，默认是16，这个值可以在构造函数中设置。<br>如果自己设置了并发度，ConcurrentHashMap 会使用大于等于该值的最小的2的幂指数作为实际并发度，也就是比如你设置的值是17，那么实际并发度是32。<br>如果并发度设置的过小，会带来严重的锁竞争问题；如果并发度设置的过大，原本位于同一个Segment内的访问会扩散到不同的Segment中，CPU cache命中率会下降，从而引起程序性能下降。</p><p>在JDK1.8中，已经摒弃了Segment的概念，选择了Node数组+链表+红黑树结构，并发度大小依赖于数组的大小。</p><h3 id="ConcurrentHashMap-迭代器是强一致性还是弱一致性？"><a href="#ConcurrentHashMap-迭代器是强一致性还是弱一致性？" class="headerlink" title="ConcurrentHashMap 迭代器是强一致性还是弱一致性？"></a>ConcurrentHashMap 迭代器是强一致性还是弱一致性？</h3><p>与 HashMap 迭代器是强一致性不同，ConcurrentHashMap 迭代器是弱一致性。<br>ConcurrentHashMap 的迭代器创建后，就会按照哈希表结构遍历每个元素，但在遍历过程中，内部元素可能会发生变化，如果变化发生在已遍历过的部分，迭代器就不会反映出来，而如果变化发生在未遍历过的部分，迭代器就会发现并反映出来，这就是弱一致性。<br>这样迭代器线程可以使用原来老的数据，而写线程也可以并发的完成改变，更重要的，这保证了多个线程并发执行的连续性和扩展性，是性能提升的关键。</p><h3 id="ConcurrentHashMap-和-Hashtable-的效率哪个更高？为什么？"><a href="#ConcurrentHashMap-和-Hashtable-的效率哪个更高？为什么？" class="headerlink" title="ConcurrentHashMap 和 Hashtable 的效率哪个更高？为什么？"></a>ConcurrentHashMap 和 Hashtable 的效率哪个更高？为什么？</h3><p>ConcurrentHashMap 的效率要高于 Hashtable，因为 Hashtable 给整个哈希表加了一把大锁从而实现线程安全。而ConcurrentHashMap 的锁粒度更低，在 JDK1.7 中采用分段锁实现线程安全，在 JDK1.8 中采用CAS+synchronized实现线程安全。</p><h3 id="具体说一下Hashtable的锁机制"><a href="#具体说一下Hashtable的锁机制" class="headerlink" title="具体说一下Hashtable的锁机制"></a>具体说一下Hashtable的锁机制</h3><p>Hashtable 是使用 synchronized来实现线程安全的，给整个哈希表加了一把大锁，多线程访问时候，只要有一个线程访问或操作该对象，那其他线程只能阻塞等待需要的锁被释放，在竞争激烈的多线程场景中性能就会非常差！</p><h3 id="多线程下安全的操作-map还有其他方法吗？"><a href="#多线程下安全的操作-map还有其他方法吗？" class="headerlink" title="多线程下安全的操作 map还有其他方法吗？"></a>多线程下安全的操作 map还有其他方法吗？</h3><p>还可以使用Collections.synchronizedMap方法，对方法进行加同步锁。<br><img src="https://img-blog.csdnimg.cn/img_convert/1e537606d716a73c972b0ebf7aa10da6.png" alt=""><br>如果传入的是 HashMap 对象，其实也是对 HashMap 做的方法做了一层包装，里面使用对象锁来保证多线程场景下，线程安全，本质也是对 HashMap 进行<strong>全表锁</strong>。在竞争激烈的多线程环境下性能依然也非常差，不推荐使用！</p><blockquote><p>补记：jdk 1.8 的put操作<br>做插入操作时，首先进入乐观锁，<br>然后，在乐观锁中判断容器是否初始化，<br>如果没初始化则初始化容器，<br>如果已经初始化，则判断该hash位置的节点是否为空，如果为空，则通过CAS操作进行插入。<br>如果该节点不为空，再判断容器是否在扩容中，如果在扩容，则帮助其扩容。<br>如果没有扩容，则进行最后一步，先加锁，然后找到hash值相同的那个节点(hash冲突)，<br>循环判断这个节点上的链表，决定做覆盖操作还是插入操作。<br>循环结束，插入完毕。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ConcurrentHashMap原理&quot;&gt;&lt;a href=&quot;#ConcurrentHashMap原理&quot; class=&quot;headerlink&quot; title=&quot;ConcurrentHashMap原理&quot;&gt;&lt;/a&gt;ConcurrentHashMap原理&lt;/h1&gt;&lt;h2 i</summary>
      
    
    
    
    <category term="java" scheme="https://github.com/louzhiqiang/louzhiqiang.github.io.git/categories/java/"/>
    
    
  </entry>
  
  <entry>
    <title>hashmap原理</title>
    <link href="https://github.com/louzhiqiang/louzhiqiang.github.io.git/2022/09/23/hashmap%E5%8E%9F%E7%90%86/"/>
    <id>https://github.com/louzhiqiang/louzhiqiang.github.io.git/2022/09/23/hashmap%E5%8E%9F%E7%90%86/</id>
    <published>2022-09-23T08:48:09.000Z</published>
    <updated>2022-09-23T13:07:55.550Z</updated>
    
    <content type="html"><![CDATA[<h1 id="hashmap原理"><a href="#hashmap原理" class="headerlink" title="hashmap原理"></a>hashmap原理</h1><p>hashmap是java中最常用，java优化也是比较多。想用好，先学好。</p><h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><p>HashMap是:数组+链表+红黑树。<br><img src="https://pics0.baidu.com/feed/b3fb43166d224f4a6a0d7e072f3a015b9922d160.png@f_auto?token=29c0e47830005f8f6e8eec430255ddd7" alt=""></p><h3 id="核心成员"><a href="#核心成员" class="headerlink" title="核心成员"></a>核心成员</h3><ul><li>默认初始容量(数组默认大小):16，2的整数次方 static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4;   </li><li>最大容量 static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; </li><li>默认负载因子 static final float DEFAULT_LOAD_FACTOR = 0.75f;装载因子用来衡量HashMap满的程度，表示当map集合中存储的数据达到当前数组大小的75%则需要进行扩容 </li><li>链表转红黑树边界static final int TREEIFY_THRESHOLD = 8; </li><li>红黑树转离链表边界static final int UNTREEIFY_THRESHOLD = 6;</li><li>哈希桶数组 transient Node&lt;K,V&gt;[] table; </li><li>实际存储的元素个数transient int size; </li><li>当map里面的数据大于这个threshold就会进行扩容 int threshold   阈值 = table.length * loadFactor</li></ul><h3 id="Node数组"><a href="#Node数组" class="headerlink" title="Node数组"></a>Node数组</h3><p>从源码可知，HashMap类中有一个非常重要的字段，就是 Node[] table，即哈希桶数组，明显它是一个Node的数组。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Node</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">Map</span>.<span class="title">Entry</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123;    </span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> hash;<span class="comment">//用来定位数组索引位置    </span></span><br><span class="line">    <span class="keyword">final</span> K key;V value;</span><br><span class="line">    Node&lt;K,V&gt; next;<span class="comment">//链表的下一个Node节点    </span></span><br><span class="line">    Node(<span class="keyword">int</span> hash, K key, V value, Node&lt;K,V&gt; next) &#123;        </span><br><span class="line">        <span class="keyword">this</span>.hash = hash;        </span><br><span class="line">        <span class="keyword">this</span>.key = key;        </span><br><span class="line">        <span class="keyword">this</span>.value = value;        </span><br><span class="line">        <span class="keyword">this</span>.next = next;    </span><br><span class="line">    &#125;      </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> K <span class="title">getKey</span><span class="params">()</span></span>&#123; </span><br><span class="line">        <span class="keyword">return</span> key; </span><br><span class="line">    &#125;    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> V <span class="title">getValue</span><span class="params">()</span></span>&#123; </span><br><span class="line">        <span class="keyword">return</span> value; </span><br><span class="line">    &#125;    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123; </span><br><span class="line">        <span class="keyword">return</span> key + <span class="string">"="</span> + value; </span><br><span class="line">    &#125;      </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">hashCode</span><span class="params">()</span> </span>&#123;        </span><br><span class="line">        <span class="keyword">return</span> Objects.hashCode(key) ^ Objects.hashCode(value);    </span><br><span class="line">    &#125;      </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> V <span class="title">setValue</span><span class="params">(V newValue)</span> </span>&#123;</span><br><span class="line">        V oldValue = value;        </span><br><span class="line">        value = newValue;        </span><br><span class="line">        <span class="keyword">return</span> oldValue;    </span><br><span class="line">    &#125;      </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">boolean</span> <span class="title">equals</span><span class="params">(Object o)</span> </span>&#123;        </span><br><span class="line">        <span class="keyword">if</span> (o == <span class="keyword">this</span>)<span class="keyword">return</span> <span class="keyword">true</span>;        </span><br><span class="line">        <span class="keyword">if</span> (o <span class="keyword">instanceof</span> Map.Entry) &#123;            </span><br><span class="line">            Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o;           </span><br><span class="line">            <span class="keyword">if</span> (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue()))<span class="keyword">return</span> <span class="keyword">true</span>;        </span><br><span class="line">        &#125;        </span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;    </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Node是HashMap的一个内部类，实现了Map.Entry接口，本质是就是一个映射(键值对)。</p><h2 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h2><p>HashMap采用哈希表来存储数据。<br>哈希表（Hash table，也叫散列表），是根据关键码值(Key value)而直接进行访问的数据结构，只要输入待查找的值即key，即可查找到其对应的值。<br><strong>哈希表其实就是数组的一种扩展，由数组演化而来。可以说，如果没有数组，就没有散列表</strong>。</p><p>哈希表中元素是由哈希函数确定的,将数据元素的关键字Key作为自变量，通过一定的函数关系（称为哈希函数），计算出的值，即为该元素的存储地址。<br>表示为：Addr = H（key）,如下图所示：<br><img src="https://pics5.baidu.com/feed/18d8bc3eb13533faef0c2bf48c1e6c1643345b8c.png@f_auto?token=f0af5565175329bc84dabc2d34126878" alt=""></p><p>有hash就会有冲突，所以如何处理冲突就成为一个核心问题。</p><h3 id="链式哈希表"><a href="#链式哈希表" class="headerlink" title="链式哈希表"></a>链式哈希表</h3><p>哈希表为解决冲突，可以采用地址法和链地址法等来解决问题，Java中HashMap采用了链地址法。<br><img src="https://pics7.baidu.com/feed/2f738bd4b31c8701d86059270cb20f260508ff70.jpeg@f_auto?token=fb1a69d6611c47b0c838c41bed5faa5c" alt=""></p><h4 id="hash函数"><a href="#hash函数" class="headerlink" title="hash函数"></a>hash函数</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*** 重新计算哈希值*/</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">hash</span><span class="params">(Object key)</span> </span>&#123;        </span><br><span class="line">    <span class="keyword">int</span> h;      </span><br><span class="line">    <span class="comment">// h = key.hashCode() 为第一步 取hashCode值     </span></span><br><span class="line">    <span class="comment">// h ^ (h &gt;&gt;&gt; 16) 为第二步 高位参与运算 </span></span><br><span class="line">    <span class="keyword">return</span> (key == <span class="keyword">null</span>) ? <span class="number">0</span> : (h = key.hashCode()) ^ (h &gt;&gt;&gt; <span class="number">16</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>计算数组槽位</p><blockquote><p>(n - 1) &amp; hash</p></blockquote><p>对key进行了hashCode运算，得到一个32位的int值h,然后用h 异或 h&gt;&gt;&gt;16位。在JDK1.8的实现中，优化了高位运算的算法，通过hashCode()的高16位异或低16位实现的：(h = k.hashCode()) ^ (h &gt;&gt;&gt; 16)。<br><img src="https://pics7.baidu.com/feed/d0c8a786c9177f3e7b0214b04202aace9e3d56ab.jpeg@f_auto?token=5c8de27e8ac0b0f17234109defcba69c" alt=""></p><p>这样做的好处是，可以将hashcode高位和低位的值进行混合做异或运算，而且混合后，低位的信息中加入了高位的信息，这样高位的信息被变相地保留了下来。</p><p>等于说计算下标时把hash的高16位也参与进来了，<strong>掺杂的元素多了</strong>，那么生成的hash值的随机性会增大，减少了hash碰撞。</p><p>h &amp; (table.length -1)来得到该对象的保存位，也就是数组的下标，而HashMap底层数组的长度总是2的n次方。</p><h4 id="为什么槽位数必须使用2-n？"><a href="#为什么槽位数必须使用2-n？" class="headerlink" title="为什么槽位数必须使用2^n？"></a>为什么槽位数必须使用2^n？</h4><p><strong>为了让哈希后的结果更加均匀。</strong><br><img src="https://pics2.baidu.com/feed/7e3e6709c93d70cf57c609b2d4114009bba12ba3.png@f_auto?token=c683ef70b4c7d40c26eb89f39aa65855" alt=""></p><p>假如槽位数不是16，而是17，则槽位计算公式变成：(17 – 1) &amp; hash<br>从上文可以看出，计算结果将会大大趋同，hashcode参加&amp;运算后被更多位的0屏蔽，计算结果只剩下两种0和16，这对于hashmap来说是一种灾难。<br>2.当length总是2的n次方时，h&amp; (length-1)运算等价于对length取模，也就是h%length，但是&amp;比%具有更高的效率。</p><blockquote><p>位运算的运算效率高于算术运算，原因是算术运算还是会被转化为位运算。</p></blockquote><h3 id="HashMap的put方法"><a href="#HashMap的put方法" class="headerlink" title="HashMap的put方法"></a>HashMap的put方法</h3><p>①.判断键值对数组table[i]是否为空或为null，否则执行resize()进行扩容；</p><p>②.根据键值key计算hash值得到插入的数组索引i，如果table[i]==null，直接新建节点添加</p><p>③.判断table[i]的首个元素是否和key一样，如果相同直接覆盖value</p><p>④.判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对</p><p>⑤.遍历table[i]，判断链表长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中执行插入操作，否则进行链表的插入操作；遍历过程中若发现key已经存在直接覆盖value即可；</p><p>⑥.插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。</p><blockquote><p>HashMap中数组长度的原始大小为16，并不是上面展示的长度，且数组的初始值都为null。</p></blockquote><p>链表的插入，在1.7版本的java，用的是头插法，会存在死循环问题。1.8版本已经迭代为尾插法。</p><blockquote><p>在Node的元素匹配中，是依靠key值的equals方法来比对的。</p></blockquote><h2 id="HashMap和Hashtable的区别"><a href="#HashMap和Hashtable的区别" class="headerlink" title="HashMap和Hashtable的区别"></a>HashMap和Hashtable的区别</h2><ol><li>底层数据结构不同:jdk1.7底层都是数组+链表,但jdk1.8 HashMap加入了红黑树</li><li>Hashtable 是不允许键或值为 null 的，HashMap 的键值则都可以为 null。</li><li>添加key-value的hash值算法不同：HashMap添加元素时，是使用自定义的哈希算法,而HashTable是直接采用key的hashCode()</li><li>实现方式不同：Hashtable 继承的是 Dictionary类，而 HashMap 继承的是 AbstractMap 类。</li><li>初始化容量不同：HashMap 的初始容量为：16，Hashtable 初始容量为：11，两者的负载因子默认都是：0.75。</li><li>扩容机制不同：当已用容量&gt;总容量 * 负载因子时，HashMap 扩容规则为当前容量翻倍，Hashtable 扩容规则为当前容量翻倍 +1。</li><li>支持的遍历种类不同：HashMap只支持Iterator遍历,而HashTable支持Iterator和Enumeration两种方式遍历</li><li>迭代器不同：HashMap的迭代器(Iterator)是fail-fast迭代器，而Hashtable的enumerator迭代器不是fail-fast的。所以当有其它线程改变了HashMap的结构（增加或者移除元素），将会抛出ConcurrentModificationException，但迭代器本身的remove()方法移除元素则不会抛出ConcurrentModificationException异常。但这并不是一个一定发生的行为，要看JVM。而Hashtable 则不会。</li><li>部分API不同：HashMap不支持contains(Object value)方法，没有重写toString()方法,而HashTable支持contains(Object value)方法，而且重写了toString()方法</li><li>同步性不同: Hashtable是同步(synchronized)的，适用于多线程环境,而hashmap不是同步的，适用于单线程环境。多个线程可以共享一个Hashtable；而如果没有正确的同步的话，多个线程是不能共享HashMap的。</li></ol><blockquote><p>由于Hashtable是线程安全的也是synchronized，所以在单线程环境下它比HashMap要慢。如果你不需要同步，只需要单一线程，那么使用HashMap性能要好过Hashtable。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;hashmap原理&quot;&gt;&lt;a href=&quot;#hashmap原理&quot; class=&quot;headerlink&quot; title=&quot;hashmap原理&quot;&gt;&lt;/a&gt;hashmap原理&lt;/h1&gt;&lt;p&gt;hashmap是java中最常用，java优化也是比较多。想用好，先学好。&lt;/p&gt;
</summary>
      
    
    
    
    <category term="java" scheme="https://github.com/louzhiqiang/louzhiqiang.github.io.git/categories/java/"/>
    
    
  </entry>
  
</feed>
